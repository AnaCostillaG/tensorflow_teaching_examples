{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "4f3CKqFUqL2-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Custom Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Generate Toy Dataset\n",
    "X1+X2 = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_train.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_train.csv\n",
    "X1,X2,Y\n",
    "2,3,5\n",
    "1,3,4\n",
    "3,-1,2\n",
    "4,0,4\n",
    "-2,2,0\n",
    "2,2,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_eval.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_eval.csv\n",
    "X1,X2,Y\n",
    "3,2,5\n",
    "3,1,4\n",
    "-2,-1,-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Input Fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def csv_input_fn(csv_path, batch_size,mode):\n",
    "    def parse_csv(line):\n",
    "      CSV_TYPES = [[0.0], [0.0],[0.0]]\n",
    "      \n",
    "      fields = tf.decode_csv(line, record_defaults=CSV_TYPES,field_delim=',')\n",
    "      \n",
    "      label = fields.pop(-1) #last value is label\n",
    "      label = tf.expand_dims(label,-1) #to be consistent shape with predictions\n",
    "      \n",
    "      #combine features into single tensor\n",
    "      features = tf.stack(fields,0)\n",
    "      \n",
    "      return features, label\n",
    "    \n",
    "    # Create a dataset containing the text lines.\n",
    "    dataset = tf.data.TextLineDataset(csv_path).skip(1) #skip header\n",
    "\n",
    "    # Parse each line.\n",
    "    dataset = dataset.map(parse_csv)\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    if(mode == tf.estimator.ModeKeys.TRAIN):\n",
    "      dataset = dataset.shuffle(batch_size*10)\n",
    "      dataset = dataset.repeat()\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create the custom estimator\n",
    "def custom_estimator(features, labels, mode, params):\n",
    "  print('custom_estimator: features: {}'.format(features))\n",
    "  print('custom_estimator: labels:{}'.format(labels))\n",
    "  \n",
    "  predictions = tf.layers.dense(features,1,activation=None)\n",
    "  print('custom_estimator: predictions: {}'.format(predictions))\n",
    "  \n",
    "  # 2. Loss function, training/eval ops\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
    "    loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "    optimizer = tf.train.FtrlOptimizer(learning_rate=0.1)\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "      loss = loss,\n",
    "      global_step = tf.train.get_global_step(),\n",
    "      learning_rate = 0.01,\n",
    "      optimizer = optimizer)\n",
    "    \n",
    "    eval_metric_ops = {\n",
    "      \"rmse\": tf.metrics.root_mean_squared_error(labels, predictions)\n",
    "    }\n",
    "  else:\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = None\n",
    "  \n",
    "  predictions_dict = {'predictions':predictions,'features':features}\n",
    "  \n",
    "  return tf.estimator.EstimatorSpec(\n",
    "    mode = mode,\n",
    "    predictions = predictions_dict,\n",
    "    loss = loss,\n",
    "    train_op = train_op,\n",
    "    eval_metric_ops = eval_metric_ops,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create custom estimator's train and evaluate function\n",
    "def train_and_evaluate(output_dir,args):\n",
    "  estimator = tf.estimator.Estimator(model_fn=custom_estimator, \n",
    "                                     model_dir=output_dir)\n",
    "  train_spec = tf.estimator.TrainSpec(input_fn= lambda:csv_input_fn(\n",
    "                                        args['train_path'],\n",
    "                                        args['batch_size'],\n",
    "                                        tf.estimator.ModeKeys.TRAIN),\n",
    "                                      max_steps = args['train_steps'])\n",
    "  eval_spec = tf.estimator.EvalSpec(input_fn = lambda:csv_input_fn(\n",
    "                                      args['eval_path'], \n",
    "                                      args['batch_size'],\n",
    "                                      tf.estimator.ModeKeys.EVAL),\n",
    "                                    steps = None)\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f892c10cad0>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': 'trained', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function custom_estimator at 0x7f8927990578>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "custom_estimator: features: Tensor(\"IteratorGetNext:0\", shape=(?, 2), dtype=float32)\n",
      "custom_estimator: labels:Tensor(\"IteratorGetNext:1\", shape=(?, 1), dtype=float32)\n",
      "custom_estimator: predictions: Tensor(\"dense/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 14.381937, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 100 into trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.16213264.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "custom_estimator: features: Tensor(\"IteratorGetNext:0\", shape=(?, 2), dtype=float32)\n",
      "custom_estimator: labels:Tensor(\"IteratorGetNext:1\", shape=(?, 1), dtype=float32)\n",
      "custom_estimator: predictions: Tensor(\"dense/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-06-29-04:35:59\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-06-29-04:36:00\n",
      "INFO:tensorflow:Saving dict for global step 100: global_step = 100, loss = 0.04452223, rmse = 0.21100292\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "  'train_path': 'data_train.csv',\n",
    "  'eval_path': 'data_eval.csv',\n",
    "  'batch_size': 4,\n",
    "  'train_steps': 100,\n",
    "}\n",
    "OUTDIR = 'trained'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "train_and_evaluate(OUTDIR,args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Inspect Weights\n",
    "\n",
    "The tensors named dense/kernel and dense/bias are the weights and bias for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_name:  dense/kernel\n",
      "[[0.37332565]\n",
      " [1.1088971 ]]\n",
      "tensor_name:  dense/bias\n",
      "[0.94920313]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.tools import inspect_checkpoint\n",
    "inspect_checkpoint.print_tensors_in_checkpoint_file(\"custom_estimator_trained_model/model.ckpt-100\", tensor_name='dense/kernel', all_tensors=False)\n",
    "inspect_checkpoint.print_tensors_in_checkpoint_file(\"custom_estimator_trained_model/model.ckpt-100\", tensor_name='dense/bias', all_tensors=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8949ceaf10>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': 'trained', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function custom_estimator at 0x7f8927990578>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "custom_estimator: features: Tensor(\"IteratorGetNext:0\", shape=(?, 2), dtype=float32)\n",
      "custom_estimator: labels:None\n",
      "custom_estimator: predictions: Tensor(\"dense/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from trained/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "{'predictions': array([[ 4.748355 ],\n",
      "       [ 3.998592 ],\n",
      "       [-1.7349727]], dtype=float32), 'features': array([[ 3.,  2.],\n",
      "       [ 3.,  1.],\n",
      "       [-2., -1.]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "#load checkpoint\n",
    "estimator = tf.estimator.Estimator(model_fn=custom_estimator, \n",
    "                                     model_dir=OUTDIR) \n",
    "\n",
    "predictions = estimator.predict(\n",
    "  input_fn = lambda:csv_input_fn(\n",
    "                  args['eval_path'], \n",
    "                  args['batch_size'],\n",
    "                  tf.estimator.ModeKeys.EVAL),\n",
    "  yield_single_examples=False\n",
    "  )\n",
    "print(predictions.next())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "first_steps_with_tensor_flow.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
