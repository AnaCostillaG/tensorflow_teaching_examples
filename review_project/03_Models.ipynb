{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_Models_using_numeric_features_+_text (2).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/vijaykyr/tensorflow_teaching_examples/blob/dev/review_project/03_Models.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "PUP4h-bMO9of",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "43b5d488-0d02-440a-fe6a-b289575f0d71"
      },
      "cell_type": "code",
      "source": [
        "import shutil, os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "pd.set_option('display.max_columns', 100)\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ezmMSpD3O9ol",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SEED=1 # for reproducibility"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pPYaKpo8T7hu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Colab initialization\n",
        "\n",
        "Remove this before publishing"
      ]
    },
    {
      "metadata": {
        "id": "T1PcaSUga0eR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "c31701f2-8642-433a-ac9f-768abdd6c9cb"
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow==1.10 # keras estimator breaks in tf 1.11, global step never increments"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow==1.10 in /usr/local/lib/python2.7/dist-packages (1.10.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.10) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.10) (3.6.1)\n",
            "Requirement already satisfied, skipping upgrade: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.10) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.10) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<=1.14.5,>=1.13.3 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.10) (1.14.5)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.10) (0.5.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.10) (0.32.1)\n",
            "Requirement already satisfied, skipping upgrade: enum34>=1.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.10) (1.1.6)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.10) (1.10.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<1.11.0,>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.10) (1.10.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.10) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: backports.weakref>=1.0rc1 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.10) (1.0.post1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools<=39.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.10) (39.1.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.10) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow==1.10) (3.2.0)\n",
            "Requirement already satisfied, skipping upgrade: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow==1.10) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow==1.10) (4.3.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.10 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10) (3.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "26_jPOHFTltb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eq_YLTvuPAjs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c3034913-1f85-4a8c-921c-5915127293ca"
      },
      "cell_type": "code",
      "source": [
        "!gcloud config set project vijays-sandbox"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6VNGP5SUO9on",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Start from engineered dataset\n",
        "\n",
        "Already includes engineered features and labels"
      ]
    },
    {
      "metadata": {
        "id": "r-LoohIoKjuh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0adf0615-2cca-4996-c42e-1165b90ed4e9"
      },
      "cell_type": "code",
      "source": [
        "!gsutil cp gs://cloud-training-demos/courses/machine_learning/asl_review_project/data.csv data.csv"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://cloud-training-demos/courses/machine_learning/asl_review_project/data.csv...\n",
            "| [1 files][325.3 MiB/325.3 MiB]                                                \n",
            "Operation completed over 1 objects/325.3 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lEml18qjQAmy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Explore Data**"
      ]
    },
    {
      "metadata": {
        "id": "oweX5F9JQHz5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "60b2c26d-1072-4b39-d374-387ace013e3e"
      },
      "cell_type": "code",
      "source": [
        "dfXy = pd.read_csv('data.csv')\n",
        "dfXy.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>surprise</th>\n",
              "      <th>reported_EPS</th>\n",
              "      <th>consensus_EPS</th>\n",
              "      <th>symbol</th>\n",
              "      <th>datetime</th>\n",
              "      <th>events</th>\n",
              "      <th>file</th>\n",
              "      <th>text</th>\n",
              "      <th>release_hr</th>\n",
              "      <th>release_minute</th>\n",
              "      <th>time_of_release</th>\n",
              "      <th>date</th>\n",
              "      <th>label</th>\n",
              "      <th>price_change</th>\n",
              "      <th>close_m_open</th>\n",
              "      <th>close_MIN_prior_5_days</th>\n",
              "      <th>close_MIN_prior_20_days</th>\n",
              "      <th>close_MIN_prior_260_days</th>\n",
              "      <th>close_MAX_prior_5_days</th>\n",
              "      <th>close_MAX_prior_20_days</th>\n",
              "      <th>close_MAX_prior_260_days</th>\n",
              "      <th>close_AVG_prior_5_days</th>\n",
              "      <th>close_AVG_prior_20_days</th>\n",
              "      <th>close_AVG_prior_260_days</th>\n",
              "      <th>close_STDDEV_prior_5_days</th>\n",
              "      <th>close_STDDEV_prior_20_days</th>\n",
              "      <th>close_STDDEV_prior_260_days</th>\n",
              "      <th>close_values_prior_260</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>A</td>\n",
              "      <td>2003-05-19 16:23:06</td>\n",
              "      <td>regulation_fd_disclosure</td>\n",
              "      <td>A/A-8K-20030519162306.txt.gz\\n</td>\n",
              "      <td>\\nITEM: Regulation FD Disclosure\\nTable of Con...</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>after</td>\n",
              "      <td>2003-05-19</td>\n",
              "      <td>UP</td>\n",
              "      <td>0.034816</td>\n",
              "      <td>-0.59</td>\n",
              "      <td>1.047066</td>\n",
              "      <td>0.985171</td>\n",
              "      <td>0.699549</td>\n",
              "      <td>1.077369</td>\n",
              "      <td>1.077369</td>\n",
              "      <td>2.001934</td>\n",
              "      <td>1.058027</td>\n",
              "      <td>1.036718</td>\n",
              "      <td>1.115747</td>\n",
              "      <td>0.012708</td>\n",
              "      <td>0.021184</td>\n",
              "      <td>0.300234</td>\n",
              "      <td>[27.81, 30.04, 28.74, 27.95, 28.46, 31.05, 29....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>71.43</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>A</td>\n",
              "      <td>2003-08-18 16:30:26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A/A-8K-20030818163026.txt.gz\\n</td>\n",
              "      <td>\\nITEM: \\nTable of Contents\\nTable of Contents...</td>\n",
              "      <td>16</td>\n",
              "      <td>30</td>\n",
              "      <td>after</td>\n",
              "      <td>2003-08-18</td>\n",
              "      <td>UP</td>\n",
              "      <td>0.035619</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.935886</td>\n",
              "      <td>0.913179</td>\n",
              "      <td>0.483081</td>\n",
              "      <td>0.969724</td>\n",
              "      <td>0.978183</td>\n",
              "      <td>0.989760</td>\n",
              "      <td>0.955476</td>\n",
              "      <td>0.951380</td>\n",
              "      <td>0.725843</td>\n",
              "      <td>0.014615</td>\n",
              "      <td>0.021125</td>\n",
              "      <td>0.131667</td>\n",
              "      <td>[16.27, 16.87, 17.2, 16.72, 16.46, 15.89, 16.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-4.55</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.22</td>\n",
              "      <td>A</td>\n",
              "      <td>2004-02-17 16:19:29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A/A-8K-20040217161929.txt.gz\\n</td>\n",
              "      <td>\\nITEM: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n...</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "      <td>after</td>\n",
              "      <td>2004-02-17</td>\n",
              "      <td>DOWN</td>\n",
              "      <td>-0.039744</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.984796</td>\n",
              "      <td>0.891971</td>\n",
              "      <td>0.305415</td>\n",
              "      <td>0.997599</td>\n",
              "      <td>0.997599</td>\n",
              "      <td>0.997599</td>\n",
              "      <td>0.991571</td>\n",
              "      <td>0.953681</td>\n",
              "      <td>0.587837</td>\n",
              "      <td>0.005472</td>\n",
              "      <td>0.034869</td>\n",
              "      <td>0.174599</td>\n",
              "      <td>[16.3, 16.32, 12.26, 11.45, 11.73, 12.05, 12.4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.24</td>\n",
              "      <td>A</td>\n",
              "      <td>2004-05-17 16:25:01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A/A-8K-20040517162501.txt.gz\\n</td>\n",
              "      <td>\\nITEM: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n...</td>\n",
              "      <td>16</td>\n",
              "      <td>25</td>\n",
              "      <td>after</td>\n",
              "      <td>2004-05-17</td>\n",
              "      <td>UP</td>\n",
              "      <td>0.026646</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.995690</td>\n",
              "      <td>0.995690</td>\n",
              "      <td>0.607759</td>\n",
              "      <td>1.026646</td>\n",
              "      <td>1.191223</td>\n",
              "      <td>1.469044</td>\n",
              "      <td>1.013950</td>\n",
              "      <td>1.079330</td>\n",
              "      <td>1.023271</td>\n",
              "      <td>0.013927</td>\n",
              "      <td>0.058654</td>\n",
              "      <td>0.216846</td>\n",
              "      <td>[16.07, 15.99, 16.02, 16.33, 16.3, 16.24, 16.2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.14</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.28</td>\n",
              "      <td>A</td>\n",
              "      <td>2004-08-12 16:53:00</td>\n",
              "      <td>results_of_operations_and_financial_condition</td>\n",
              "      <td>A/A-8K-20040812165300.txt.gz\\n</td>\n",
              "      <td>\\nITEM: Results of Operations and Financial Co...</td>\n",
              "      <td>16</td>\n",
              "      <td>53</td>\n",
              "      <td>after</td>\n",
              "      <td>2004-08-12</td>\n",
              "      <td>UP</td>\n",
              "      <td>0.086382</td>\n",
              "      <td>-2.10</td>\n",
              "      <td>1.106199</td>\n",
              "      <td>1.106199</td>\n",
              "      <td>1.045732</td>\n",
              "      <td>1.161585</td>\n",
              "      <td>1.313008</td>\n",
              "      <td>1.904980</td>\n",
              "      <td>1.128354</td>\n",
              "      <td>1.201347</td>\n",
              "      <td>1.400917</td>\n",
              "      <td>0.024174</td>\n",
              "      <td>0.063852</td>\n",
              "      <td>0.210281</td>\n",
              "      <td>[21.73, 21.55, 21.56, 20.83, 20.58, 20.67, 20....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   surprise  reported_EPS  consensus_EPS symbol             datetime  \\\n",
              "0      0.00         -0.15          -0.15      A  2003-05-19 16:23:06   \n",
              "1     71.43         -0.02          -0.07      A  2003-08-18 16:30:26   \n",
              "2     -4.55          0.21           0.22      A  2004-02-17 16:19:29   \n",
              "3      0.00          0.24           0.24      A  2004-05-17 16:25:01   \n",
              "4      7.14          0.30           0.28      A  2004-08-12 16:53:00   \n",
              "\n",
              "                                          events  \\\n",
              "0                       regulation_fd_disclosure   \n",
              "1                                            NaN   \n",
              "2                                            NaN   \n",
              "3                                            NaN   \n",
              "4  results_of_operations_and_financial_condition   \n",
              "\n",
              "                             file  \\\n",
              "0  A/A-8K-20030519162306.txt.gz\\n   \n",
              "1  A/A-8K-20030818163026.txt.gz\\n   \n",
              "2  A/A-8K-20040217161929.txt.gz\\n   \n",
              "3  A/A-8K-20040517162501.txt.gz\\n   \n",
              "4  A/A-8K-20040812165300.txt.gz\\n   \n",
              "\n",
              "                                                text  release_hr  \\\n",
              "0  \\nITEM: Regulation FD Disclosure\\nTable of Con...          16   \n",
              "1  \\nITEM: \\nTable of Contents\\nTable of Contents...          16   \n",
              "2  \\nITEM: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n...          16   \n",
              "3  \\nITEM: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n...          16   \n",
              "4  \\nITEM: Results of Operations and Financial Co...          16   \n",
              "\n",
              "   release_minute time_of_release        date label  price_change  \\\n",
              "0              23           after  2003-05-19    UP      0.034816   \n",
              "1              30           after  2003-08-18    UP      0.035619   \n",
              "2              19           after  2004-02-17  DOWN     -0.039744   \n",
              "3              25           after  2004-05-17    UP      0.026646   \n",
              "4              53           after  2004-08-12    UP      0.086382   \n",
              "\n",
              "   close_m_open  close_MIN_prior_5_days  close_MIN_prior_20_days  \\\n",
              "0         -0.59                1.047066                 0.985171   \n",
              "1          0.68                0.935886                 0.913179   \n",
              "2          0.41                0.984796                 0.891971   \n",
              "3          0.07                0.995690                 0.995690   \n",
              "4         -2.10                1.106199                 1.106199   \n",
              "\n",
              "   close_MIN_prior_260_days  close_MAX_prior_5_days  close_MAX_prior_20_days  \\\n",
              "0                  0.699549                1.077369                 1.077369   \n",
              "1                  0.483081                0.969724                 0.978183   \n",
              "2                  0.305415                0.997599                 0.997599   \n",
              "3                  0.607759                1.026646                 1.191223   \n",
              "4                  1.045732                1.161585                 1.313008   \n",
              "\n",
              "   close_MAX_prior_260_days  close_AVG_prior_5_days  close_AVG_prior_20_days  \\\n",
              "0                  2.001934                1.058027                 1.036718   \n",
              "1                  0.989760                0.955476                 0.951380   \n",
              "2                  0.997599                0.991571                 0.953681   \n",
              "3                  1.469044                1.013950                 1.079330   \n",
              "4                  1.904980                1.128354                 1.201347   \n",
              "\n",
              "   close_AVG_prior_260_days  close_STDDEV_prior_5_days  \\\n",
              "0                  1.115747                   0.012708   \n",
              "1                  0.725843                   0.014615   \n",
              "2                  0.587837                   0.005472   \n",
              "3                  1.023271                   0.013927   \n",
              "4                  1.400917                   0.024174   \n",
              "\n",
              "   close_STDDEV_prior_20_days  close_STDDEV_prior_260_days  \\\n",
              "0                    0.021184                     0.300234   \n",
              "1                    0.021125                     0.131667   \n",
              "2                    0.034869                     0.174599   \n",
              "3                    0.058654                     0.216846   \n",
              "4                    0.063852                     0.210281   \n",
              "\n",
              "                              close_values_prior_260  \n",
              "0  [27.81, 30.04, 28.74, 27.95, 28.46, 31.05, 29....  \n",
              "1  [16.27, 16.87, 17.2, 16.72, 16.46, 15.89, 16.0...  \n",
              "2  [16.3, 16.32, 12.26, 11.45, 11.73, 12.05, 12.4...  \n",
              "3  [16.07, 15.99, 16.02, 16.33, 16.3, 16.24, 16.2...  \n",
              "4  [21.73, 21.55, 21.56, 20.83, 20.58, 20.67, 20....  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "7_RecK3HO9or",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "f33407be-fda7-4613-a7ab-0f4cdbb1cbaf"
      },
      "cell_type": "code",
      "source": [
        "dfXy = dfXy.dropna() # remove rows with null values\n",
        "dfXy.describe()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>surprise</th>\n",
              "      <th>reported_EPS</th>\n",
              "      <th>consensus_EPS</th>\n",
              "      <th>release_hr</th>\n",
              "      <th>release_minute</th>\n",
              "      <th>price_change</th>\n",
              "      <th>close_m_open</th>\n",
              "      <th>close_MIN_prior_5_days</th>\n",
              "      <th>close_MIN_prior_20_days</th>\n",
              "      <th>close_MIN_prior_260_days</th>\n",
              "      <th>close_MAX_prior_5_days</th>\n",
              "      <th>close_MAX_prior_20_days</th>\n",
              "      <th>close_MAX_prior_260_days</th>\n",
              "      <th>close_AVG_prior_5_days</th>\n",
              "      <th>close_AVG_prior_20_days</th>\n",
              "      <th>close_AVG_prior_260_days</th>\n",
              "      <th>close_STDDEV_prior_5_days</th>\n",
              "      <th>close_STDDEV_prior_20_days</th>\n",
              "      <th>close_STDDEV_prior_260_days</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>14351.000000</td>\n",
              "      <td>14351.000000</td>\n",
              "      <td>14351.000000</td>\n",
              "      <td>14351.000000</td>\n",
              "      <td>14351.000000</td>\n",
              "      <td>14351.000000</td>\n",
              "      <td>14351.000000</td>\n",
              "      <td>14351.000000</td>\n",
              "      <td>14351.000000</td>\n",
              "      <td>14351.000000</td>\n",
              "      <td>14351.000000</td>\n",
              "      <td>14351.000000</td>\n",
              "      <td>14351.000000</td>\n",
              "      <td>14351.000000</td>\n",
              "      <td>14351.000000</td>\n",
              "      <td>14351.000000</td>\n",
              "      <td>14351.000000</td>\n",
              "      <td>14351.000000</td>\n",
              "      <td>14351.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.168222</td>\n",
              "      <td>0.728475</td>\n",
              "      <td>0.717198</td>\n",
              "      <td>11.369870</td>\n",
              "      <td>24.464567</td>\n",
              "      <td>0.001728</td>\n",
              "      <td>0.015911</td>\n",
              "      <td>0.977410</td>\n",
              "      <td>0.941194</td>\n",
              "      <td>0.752378</td>\n",
              "      <td>1.021649</td>\n",
              "      <td>1.058376</td>\n",
              "      <td>1.332590</td>\n",
              "      <td>0.999480</td>\n",
              "      <td>0.999513</td>\n",
              "      <td>1.035995</td>\n",
              "      <td>0.018126</td>\n",
              "      <td>0.034813</td>\n",
              "      <td>0.149644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>369.845604</td>\n",
              "      <td>2.559523</td>\n",
              "      <td>0.752646</td>\n",
              "      <td>4.283074</td>\n",
              "      <td>16.968143</td>\n",
              "      <td>0.043719</td>\n",
              "      <td>2.030058</td>\n",
              "      <td>0.052699</td>\n",
              "      <td>0.073846</td>\n",
              "      <td>0.165629</td>\n",
              "      <td>0.070620</td>\n",
              "      <td>0.125448</td>\n",
              "      <td>1.243288</td>\n",
              "      <td>0.054224</td>\n",
              "      <td>0.084827</td>\n",
              "      <td>0.540218</td>\n",
              "      <td>0.027083</td>\n",
              "      <td>0.041305</td>\n",
              "      <td>0.415959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-38300.000000</td>\n",
              "      <td>-283.400000</td>\n",
              "      <td>-16.980000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.998461</td>\n",
              "      <td>-60.540000</td>\n",
              "      <td>0.000303</td>\n",
              "      <td>0.000303</td>\n",
              "      <td>0.000276</td>\n",
              "      <td>0.716792</td>\n",
              "      <td>0.820030</td>\n",
              "      <td>0.836735</td>\n",
              "      <td>0.595825</td>\n",
              "      <td>0.522218</td>\n",
              "      <td>0.138430</td>\n",
              "      <td>0.000718</td>\n",
              "      <td>0.003070</td>\n",
              "      <td>0.019525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>-0.016221</td>\n",
              "      <td>-0.570000</td>\n",
              "      <td>0.954355</td>\n",
              "      <td>0.910638</td>\n",
              "      <td>0.664773</td>\n",
              "      <td>0.992259</td>\n",
              "      <td>1.004405</td>\n",
              "      <td>1.042547</td>\n",
              "      <td>0.974775</td>\n",
              "      <td>0.961044</td>\n",
              "      <td>0.877483</td>\n",
              "      <td>0.008697</td>\n",
              "      <td>0.016786</td>\n",
              "      <td>0.067255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.600000</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000692</td>\n",
              "      <td>-0.010000</td>\n",
              "      <td>0.980378</td>\n",
              "      <td>0.951072</td>\n",
              "      <td>0.775554</td>\n",
              "      <td>1.013953</td>\n",
              "      <td>1.031660</td>\n",
              "      <td>1.129253</td>\n",
              "      <td>0.997408</td>\n",
              "      <td>0.992013</td>\n",
              "      <td>0.962872</td>\n",
              "      <td>0.013611</td>\n",
              "      <td>0.025127</td>\n",
              "      <td>0.096834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>10.770000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>0.020236</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>1.003014</td>\n",
              "      <td>0.982435</td>\n",
              "      <td>0.869574</td>\n",
              "      <td>1.040982</td>\n",
              "      <td>1.075391</td>\n",
              "      <td>1.345239</td>\n",
              "      <td>1.020761</td>\n",
              "      <td>1.027671</td>\n",
              "      <td>1.084247</td>\n",
              "      <td>0.021517</td>\n",
              "      <td>0.039368</td>\n",
              "      <td>0.153940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7900.000000</td>\n",
              "      <td>13.870000</td>\n",
              "      <td>10.650000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>0.430416</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.601758</td>\n",
              "      <td>1.598956</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>4.968535</td>\n",
              "      <td>5.172387</td>\n",
              "      <td>124.404762</td>\n",
              "      <td>2.559268</td>\n",
              "      <td>4.416486</td>\n",
              "      <td>48.571245</td>\n",
              "      <td>2.168584</td>\n",
              "      <td>1.484452</td>\n",
              "      <td>43.286283</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           surprise  reported_EPS  consensus_EPS    release_hr  \\\n",
              "count  14351.000000  14351.000000   14351.000000  14351.000000   \n",
              "mean       2.168222      0.728475       0.717198     11.369870   \n",
              "std      369.845604      2.559523       0.752646      4.283074   \n",
              "min   -38300.000000   -283.400000     -16.980000      6.000000   \n",
              "25%        0.000000      0.350000       0.340000      8.000000   \n",
              "50%        3.600000      0.610000       0.590000      9.000000   \n",
              "75%       10.770000      1.000000       0.960000     16.000000   \n",
              "max     7900.000000     13.870000      10.650000     21.000000   \n",
              "\n",
              "       release_minute  price_change  close_m_open  close_MIN_prior_5_days  \\\n",
              "count    14351.000000  14351.000000  14351.000000            14351.000000   \n",
              "mean        24.464567      0.001728      0.015911                0.977410   \n",
              "std         16.968143      0.043719      2.030058                0.052699   \n",
              "min          0.000000     -0.998461    -60.540000                0.000303   \n",
              "25%         10.000000     -0.016221     -0.570000                0.954355   \n",
              "50%         22.000000      0.000692     -0.010000                0.980378   \n",
              "75%         38.000000      0.020236      0.550000                1.003014   \n",
              "max         59.000000      0.430416     41.000000                1.601758   \n",
              "\n",
              "       close_MIN_prior_20_days  close_MIN_prior_260_days  \\\n",
              "count             14351.000000              14351.000000   \n",
              "mean                  0.941194                  0.752378   \n",
              "std                   0.073846                  0.165629   \n",
              "min                   0.000303                  0.000276   \n",
              "25%                   0.910638                  0.664773   \n",
              "50%                   0.951072                  0.775554   \n",
              "75%                   0.982435                  0.869574   \n",
              "max                   1.598956                  1.400000   \n",
              "\n",
              "       close_MAX_prior_5_days  close_MAX_prior_20_days  \\\n",
              "count            14351.000000             14351.000000   \n",
              "mean                 1.021649                 1.058376   \n",
              "std                  0.070620                 0.125448   \n",
              "min                  0.716792                 0.820030   \n",
              "25%                  0.992259                 1.004405   \n",
              "50%                  1.013953                 1.031660   \n",
              "75%                  1.040982                 1.075391   \n",
              "max                  4.968535                 5.172387   \n",
              "\n",
              "       close_MAX_prior_260_days  close_AVG_prior_5_days  \\\n",
              "count              14351.000000            14351.000000   \n",
              "mean                   1.332590                0.999480   \n",
              "std                    1.243288                0.054224   \n",
              "min                    0.836735                0.595825   \n",
              "25%                    1.042547                0.974775   \n",
              "50%                    1.129253                0.997408   \n",
              "75%                    1.345239                1.020761   \n",
              "max                  124.404762                2.559268   \n",
              "\n",
              "       close_AVG_prior_20_days  close_AVG_prior_260_days  \\\n",
              "count             14351.000000              14351.000000   \n",
              "mean                  0.999513                  1.035995   \n",
              "std                   0.084827                  0.540218   \n",
              "min                   0.522218                  0.138430   \n",
              "25%                   0.961044                  0.877483   \n",
              "50%                   0.992013                  0.962872   \n",
              "75%                   1.027671                  1.084247   \n",
              "max                   4.416486                 48.571245   \n",
              "\n",
              "       close_STDDEV_prior_5_days  close_STDDEV_prior_20_days  \\\n",
              "count               14351.000000                14351.000000   \n",
              "mean                    0.018126                    0.034813   \n",
              "std                     0.027083                    0.041305   \n",
              "min                     0.000718                    0.003070   \n",
              "25%                     0.008697                    0.016786   \n",
              "50%                     0.013611                    0.025127   \n",
              "75%                     0.021517                    0.039368   \n",
              "max                     2.168584                    1.484452   \n",
              "\n",
              "       close_STDDEV_prior_260_days  \n",
              "count                 14351.000000  \n",
              "mean                      0.149644  \n",
              "std                       0.415959  \n",
              "min                       0.019525  \n",
              "25%                       0.067255  \n",
              "50%                       0.096834  \n",
              "75%                       0.153940  \n",
              "max                      43.286283  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "UVR3Nf50O9o3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### DNN Using Only Numeric Features\n",
        "\n",
        "47.64%"
      ]
    },
    {
      "metadata": {
        "id": "dvb74PJkO9oy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "11adc102-7ce5-4dc0-df1f-f8000c17a2cc"
      },
      "cell_type": "code",
      "source": [
        "#Select features\n",
        "ix_price_features = dfXy.columns.str.contains('close_')\n",
        "price_features = dfXy.columns[ix_price_features].tolist()\n",
        "price_features.remove('close_values_prior_260') # For RNN, which is a list. We don't want.\n",
        "FEATURES = price_features + ['surprise'] \n",
        "FEATURES"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['close_m_open',\n",
              " 'close_MIN_prior_5_days',\n",
              " 'close_MIN_prior_20_days',\n",
              " 'close_MIN_prior_260_days',\n",
              " 'close_MAX_prior_5_days',\n",
              " 'close_MAX_prior_20_days',\n",
              " 'close_MAX_prior_260_days',\n",
              " 'close_AVG_prior_5_days',\n",
              " 'close_AVG_prior_20_days',\n",
              " 'close_AVG_prior_260_days',\n",
              " 'close_STDDEV_prior_5_days',\n",
              " 'close_STDDEV_prior_20_days',\n",
              " 'close_STDDEV_prior_260_days',\n",
              " 'surprise']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "hq5X_sb8Qk4a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create Train/Eval Datasets\n",
        "np.random.seed(0) # this is the only seed that isn't parameterized because the data split should never change\n",
        "msk = np.random.rand(len(dfXy)) < 0.8 \n",
        "traindf = dfXy[msk].copy()\n",
        "evaldf = dfXy[~msk].copy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4YpYOVlOO9o3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Convert string labels to numeric\n",
        "traindf['label_numeric'] = traindf.label.apply(lambda x: {'DOWN': 0, 'STAY': 1, 'UP':2}[x])\n",
        "evaldf['label_numeric'] = evaldf.label.apply(lambda x: {'DOWN': 0, 'STAY': 1, 'UP':2}[x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VG6AKXUiO9o6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "e75ebdcb-e5da-4299-81a7-f99e4e4c3045"
      },
      "cell_type": "code",
      "source": [
        "###Hyperparameters\n",
        "dropout_rate=0\n",
        "units=10\n",
        "input_shape = [len(FEATURES)]\n",
        "num_classes=3\n",
        "loss = 'sparse_categorical_crossentropy'\n",
        "learning_rate=1e-3\n",
        "epochs=10\n",
        "batch_size=128\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Embedding\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "np.random.seed(SEED)\n",
        "tf.set_random_seed(SEED) \n",
        "\n",
        "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(Dense(units=units, input_shape=input_shape, activation='relu', kernel_initializer=tf.glorot_uniform_initializer(seed=SEED)))\n",
        "model.add(Dropout(rate=dropout_rate,seed=SEED))\n",
        "model.add(Dense(units=num_classes, activation='softmax', kernel_initializer=tf.glorot_uniform_initializer(seed=SEED)))\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\n",
        "\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=3)]\n",
        "\n",
        "history = model.fit(\n",
        "        traindf[FEATURES],\n",
        "        traindf.label_numeric,\n",
        "        callbacks=callbacks,\n",
        "        epochs=epochs,\n",
        "        validation_data=(evaldf[FEATURES], evaldf.label_numeric),\n",
        "        verbose=2,  # Logs once per epoch.\n",
        "        batch_size=batch_size)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11530 samples, validate on 2821 samples\n",
            "Epoch 1/10\n",
            " - 0s - loss: 1.3782 - acc: 0.3876 - val_loss: 1.1623 - val_acc: 0.4201\n",
            "Epoch 2/10\n",
            " - 0s - loss: 1.0864 - acc: 0.4554 - val_loss: 1.0630 - val_acc: 0.4608\n",
            "Epoch 3/10\n",
            " - 0s - loss: 1.0705 - acc: 0.4641 - val_loss: 1.0793 - val_acc: 0.4566\n",
            "Epoch 4/10\n",
            " - 0s - loss: 1.0539 - acc: 0.4656 - val_loss: 1.0794 - val_acc: 0.4583\n",
            "Epoch 5/10\n",
            " - 0s - loss: 1.0591 - acc: 0.4686 - val_loss: 1.0534 - val_acc: 0.4700\n",
            "Epoch 6/10\n",
            " - 0s - loss: 1.0478 - acc: 0.4698 - val_loss: 1.0392 - val_acc: 0.4725\n",
            "Epoch 7/10\n",
            " - 0s - loss: 1.0457 - acc: 0.4711 - val_loss: 1.0384 - val_acc: 0.4722\n",
            "Epoch 8/10\n",
            " - 0s - loss: 1.0571 - acc: 0.4671 - val_loss: 1.0459 - val_acc: 0.4743\n",
            "Epoch 9/10\n",
            " - 0s - loss: 1.0415 - acc: 0.4721 - val_loss: 1.0443 - val_acc: 0.4754\n",
            "Epoch 10/10\n",
            " - 0s - loss: 1.0471 - acc: 0.4717 - val_loss: 1.0615 - val_acc: 0.4764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KhizoyOAeMp_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "aa68afbc-e4d0-47d2-8188-d3f3a20ed2c9"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10)                150       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 33        \n",
            "=================================================================\n",
            "Total params: 183\n",
            "Trainable params: 183\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SbMje8ehqXNO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create bag of words representation of 8Ks\n",
        "\n",
        "Takes 2min to run"
      ]
    },
    {
      "metadata": {
        "id": "_2vgVauiO9o9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "acb58d64-ab61-46dc-f60f-d1eea8be9c22"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Select top 'k' of the vectorized features.\n",
        "TOP_K = 2000 \n",
        "# Range (inclusive) of n-gram sizes for tokenizing text.\n",
        "NGRAM_RANGE = (1, 1)\n",
        "# Minimum document/corpus frequency below which a token will be discarded.\n",
        "MIN_DOCUMENT_FREQUENCY = 5\n",
        "\n",
        "vectorizer = CountVectorizer(\n",
        "    ngram_range=NGRAM_RANGE,\n",
        "    strip_accents='unicode',\n",
        "    stop_words='english',\n",
        "    min_df=MIN_DOCUMENT_FREQUENCY,\n",
        "    ) # returns sklearn.feature_extraction.text.CountVectorizer\n",
        "\n",
        "x_train_text = vectorizer.fit_transform(traindf.text) #takes ~2min, returns scipy.sparse.csr.csr_matrix\n",
        "x_val_text = vectorizer.transform(evaldf.text)\n",
        "print('{} tokens identified'.format(len(vectorizer.get_feature_names())))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28171 tokens identified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hnsCOeAiqkMM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Select 2000 most important tokens using f_classif**\n",
        "\n",
        "Score each of the 28171 tokens based on their predictiveness of the label. Keep only the 2000 highest scoring tokens"
      ]
    },
    {
      "metadata": {
        "id": "8-D_E-1LO9pA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a337927f-f715-4201-e623-a3146a4b89e3"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "selector = SelectKBest(f_classif, k=min(TOP_K, x_train_text.shape[1]))\n",
        "selector.fit(x_train_text, traindf.label_numeric)\n",
        "print('x_train_text shape before feature selection: {}'.format(x_train_text.shape))\n",
        "x_train_text = selector.transform(x_train_text)\n",
        "x_val_text = selector.transform(x_val_text)\n",
        "print('x_train_text shape after feature selection: {}'.format(x_train_text.shape))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train_text shape before feature selection: (11530, 28171)\n",
            "x_train_text shape after feature selection: (11530, 2000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OtggtQfcqoRP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Display Tokens**\n",
        "\n",
        "Sorted to show highest scoring first"
      ]
    },
    {
      "metadata": {
        "id": "r4oLXx1Fqrh4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17307
        },
        "outputId": "5ac8ccae-a4cf-420f-c675-53e328f3b5e5"
      },
      "cell_type": "code",
      "source": [
        "feature_names = vectorizer.get_feature_names()\n",
        "token_list = []\n",
        "for i in selector.get_support(indices=True):\n",
        "    token_list.append((round(selector.scores_[i],2),feature_names[i]))\n",
        "\n",
        "sorted(token_list, reverse=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(81.49, u'electric'),\n",
              " (64.73, u'weather'),\n",
              " (64.08, u'energy'),\n",
              " (42.12, u'trademarks'),\n",
              " (41.44, u'utility'),\n",
              " (40.19, u'regulated'),\n",
              " (38.28, u'earnings'),\n",
              " (35.73, u'generation'),\n",
              " (34.58, u'utilities'),\n",
              " (33.36, u'transmission'),\n",
              " (30.62, u'fiscal'),\n",
              " (30.22, u'megawatts'),\n",
              " (28.86, u'maintenance'),\n",
              " (26.4, u'competitors'),\n",
              " (26.07, u'2003'),\n",
              " (25.87, u'gaap'),\n",
              " (25.53, u'generating'),\n",
              " (25.3, u'cents'),\n",
              " (24.37, u'2004'),\n",
              " (23.81, u'regulatory'),\n",
              " (23.76, u'normal'),\n",
              " (23.43, u'electricity'),\n",
              " (23.13, u'communicating'),\n",
              " (22.53, u'summary'),\n",
              " (22.4, u'unregulated'),\n",
              " (22.37, u'plant'),\n",
              " (21.96, u'territory'),\n",
              " (21.64, u'mechanisms'),\n",
              " (21.54, u'projects'),\n",
              " (21.16, u'calif'),\n",
              " (20.79, u'afudc'),\n",
              " (20.65, u'2008'),\n",
              " (20.62, u'annually'),\n",
              " (20.58, u'decommissioning'),\n",
              " (20.48, u'press'),\n",
              " (20.29, u'outage'),\n",
              " (20.04, u'wisconsin'),\n",
              " (19.68, u'profile'),\n",
              " (19.57, u'warmer'),\n",
              " (19.41, u'generator'),\n",
              " (18.87, u'megawatt'),\n",
              " (18.75, u'outages'),\n",
              " (18.61, u'power'),\n",
              " (18.13, u'technology'),\n",
              " (17.67, u'cpuc'),\n",
              " (17.33, u'illinois'),\n",
              " (17.0, u'2006'),\n",
              " (16.89, u'heating'),\n",
              " (16.74, u'sensitivities'),\n",
              " (16.46, u'share'),\n",
              " (16.37, u'difficult'),\n",
              " (16.33, u'owns'),\n",
              " (16.25, u'non'),\n",
              " (16.15, u'farrell'),\n",
              " (16.11, u'software'),\n",
              " (16.08, u'ffo'),\n",
              " (16.06, u'approved'),\n",
              " (16.01, u'enterprise'),\n",
              " (15.99, u'wec'),\n",
              " (15.83, u'reits'),\n",
              " (15.65, u'wisconsinenergy'),\n",
              " (15.59, u'measures'),\n",
              " (15.55, u'7226'),\n",
              " (15.55, u'4059'),\n",
              " (15.55, u'0179'),\n",
              " (15.39, u'corporation'),\n",
              " (15.27, u'xel'),\n",
              " (15.1, u'southeastern'),\n",
              " (14.83, u'mobile'),\n",
              " (14.78, u'2005'),\n",
              " (14.75, u'xcelenergy'),\n",
              " (14.75, u'sources'),\n",
              " (14.63, u'renewable'),\n",
              " (14.63, u'recovery'),\n",
              " (14.6, u'jr'),\n",
              " (14.59, u'edison'),\n",
              " (14.57, u'governance'),\n",
              " (14.56, u'feet'),\n",
              " (14.54, u'phenomena'),\n",
              " (14.44, u'captions'),\n",
              " (14.24, u'reit'),\n",
              " (14.21, u'discussed'),\n",
              " (14.2, u'deregulation'),\n",
              " (14.12, u'55'),\n",
              " (14.1, u'recommended'),\n",
              " (14.07, u'thereunto'),\n",
              " (14.07, u'guidance'),\n",
              " (14.0, u'consistency'),\n",
              " (13.97, u'joint'),\n",
              " (13.92, u'4444'),\n",
              " (13.88, u'hour'),\n",
              " (13.87, u'estate'),\n",
              " (13.85, u'networking'),\n",
              " (13.84, u'substitute'),\n",
              " (13.8, u'sequentially'),\n",
              " (13.78, u'plants'),\n",
              " (13.75, u'forecasting'),\n",
              " (13.61, u'energies'),\n",
              " (13.6, u'pipelines'),\n",
              " (13.47, u'operation'),\n",
              " (13.46, u'cooling'),\n",
              " (13.43, u'statistics'),\n",
              " (13.33, u'environment'),\n",
              " (13.28, u'gas'),\n",
              " (13.23, u'mechanism'),\n",
              " (13.21, u'nuclear'),\n",
              " (13.19, u'reaffirmed'),\n",
              " (13.12, u'transporters'),\n",
              " (13.12, u'discontinued'),\n",
              " (13.04, u'plans'),\n",
              " (13.03, u'fad'),\n",
              " (13.0, u'factor'),\n",
              " (12.97, u'sunnyvale'),\n",
              " (12.94, u'final'),\n",
              " (12.93, u'initiation'),\n",
              " (12.89, u'ni'),\n",
              " (12.83, u'dominion'),\n",
              " (12.77, u'reliability'),\n",
              " (12.76, u'xcel'),\n",
              " (12.75, u'utilitys'),\n",
              " (12.75, u'resellers'),\n",
              " (12.63, u'native'),\n",
              " (12.6, u'southeast'),\n",
              " (12.56, u'coli'),\n",
              " (12.51, u'2002'),\n",
              " (12.41, u'dairy'),\n",
              " (12.4, u'isolation'),\n",
              " (12.39, u'indiana'),\n",
              " (12.34, u'equivalent'),\n",
              " (12.33, u'mcgrath'),\n",
              " (12.28, u'shown'),\n",
              " (12.27, u'sale'),\n",
              " (12.24, u'remediate'),\n",
              " (12.16, u'combined'),\n",
              " (12.13, u'divestitures'),\n",
              " (12.13, u'computing'),\n",
              " (12.11, u'peninsula'),\n",
              " (12.1, u'gigawatt'),\n",
              " (12.07, u'straight'),\n",
              " (12.07, u'115'),\n",
              " (12.06, u'old'),\n",
              " (12.04, u'kwh'),\n",
              " (11.93, u'properties'),\n",
              " (11.93, u'center'),\n",
              " (11.91, u'hereunto'),\n",
              " (11.86, u'tenants'),\n",
              " (11.86, u'alabama'),\n",
              " (11.81, u'df'),\n",
              " (11.77, u'restoration'),\n",
              " (11.75, u'bodies'),\n",
              " (11.71, u'revenue'),\n",
              " (11.68, u'kilowatt'),\n",
              " (11.68, u'ind'),\n",
              " (11.66, u'industrial'),\n",
              " (11.66, u'acts'),\n",
              " (11.65, u'virtualization'),\n",
              " (11.59, u'psco'),\n",
              " (11.57, u'population'),\n",
              " (11.55, u'klappa'),\n",
              " (11.54, u'construction'),\n",
              " (11.52, u'bases'),\n",
              " (11.51, u'theodore'),\n",
              " (11.49, u'corridor'),\n",
              " (11.49, u'110'),\n",
              " (11.44, u'flat'),\n",
              " (11.44, u'appendices'),\n",
              " (11.42, u'minnesota'),\n",
              " (11.41, u'1934'),\n",
              " (11.33, u'includible'),\n",
              " (11.33, u'gale'),\n",
              " (11.33, u'anchor'),\n",
              " (11.31, u'storms'),\n",
              " (11.28, u'printable'),\n",
              " (11.27, u'rent'),\n",
              " (11.23, u'publish'),\n",
              " (11.19, u'fd'),\n",
              " (11.14, u'editors'),\n",
              " (11.13, u'legislature'),\n",
              " (11.12, u'refueling'),\n",
              " (11.11, u'traffic'),\n",
              " (11.07, u'sunday'),\n",
              " (11.03, u'station'),\n",
              " (10.97, u'budgeting'),\n",
              " (10.95, u'taxable'),\n",
              " (10.94, u'conservation'),\n",
              " (10.94, u'completed'),\n",
              " (10.9, u'real'),\n",
              " (10.88, u'refinance'),\n",
              " (10.86, u'particulate'),\n",
              " (10.85, u'submitted'),\n",
              " (10.85, u'midwest'),\n",
              " (10.84, u'80'),\n",
              " (10.75, u'treatment'),\n",
              " (10.75, u'mild'),\n",
              " (10.68, u'proxies'),\n",
              " (10.67, u'facilitates'),\n",
              " (10.65, u'25'),\n",
              " (10.64, u'legislative'),\n",
              " (10.64, u'704'),\n",
              " (10.63, u'sault'),\n",
              " (10.63, u'5333'),\n",
              " (10.62, u'warm'),\n",
              " (10.61, u'serving'),\n",
              " (10.59, u'tele'),\n",
              " (10.57, u'post'),\n",
              " (10.56, u'turbine'),\n",
              " (10.56, u'status'),\n",
              " (10.55, u'early'),\n",
              " (10.51, u'milder'),\n",
              " (10.5, u'gross'),\n",
              " (10.49, u'skaggs'),\n",
              " (10.49, u'sce'),\n",
              " (10.4, u'earned'),\n",
              " (10.37, u'89'),\n",
              " (10.36, u'bills'),\n",
              " (10.35, u'located'),\n",
              " (10.35, u'alt'),\n",
              " (10.33, u'employee'),\n",
              " (10.31, u'deteriorating'),\n",
              " (10.3, u'commodities'),\n",
              " (10.29, u'proxy'),\n",
              " (10.27, u'nisource'),\n",
              " (10.27, u'degree'),\n",
              " (10.26, u'unplanned'),\n",
              " (10.23, u'interpret'),\n",
              " (10.21, u'attention'),\n",
              " (10.16, u'smarter'),\n",
              " (10.15, u'excellent'),\n",
              " (10.14, u'square'),\n",
              " (10.12, u'mercury'),\n",
              " (10.08, u'service'),\n",
              " (10.06, u'pcg'),\n",
              " (10.06, u'3322'),\n",
              " (10.05, u'70113'),\n",
              " (10.04, u'replay'),\n",
              " (10.04, u'qualify'),\n",
              " (10.03, u'02199'),\n",
              " (10.02, u'publications'),\n",
              " (10.0, u'public'),\n",
              " (9.97, u'rapid'),\n",
              " (9.97, u'includes'),\n",
              " (9.94, u'rolled'),\n",
              " (9.94, u'leasing'),\n",
              " (9.93, u'gla'),\n",
              " (9.93, u'features'),\n",
              " (9.92, u'product'),\n",
              " (9.92, u'400'),\n",
              " (9.89, u'southerncompany'),\n",
              " (9.88, u'tobacco'),\n",
              " (9.86, u'workforce'),\n",
              " (9.86, u'offerings'),\n",
              " (9.86, u'dom'),\n",
              " (9.85, u'phase'),\n",
              " (9.85, u'nsp'),\n",
              " (9.83, u'negotiations'),\n",
              " (9.83, u'charlotte'),\n",
              " (9.82, u'industry'),\n",
              " (9.8, u'holds'),\n",
              " (9.8, u'2592'),\n",
              " (9.78, u'ratemaking'),\n",
              " (9.78, u'load'),\n",
              " (9.78, u'eix'),\n",
              " (9.77, u'135'),\n",
              " (9.76, u'southern'),\n",
              " (9.75, u'96'),\n",
              " (9.75, u'12'),\n",
              " (9.74, u'softer'),\n",
              " (9.74, u'91'),\n",
              " (9.73, u'adult'),\n",
              " (9.72, u'reduces'),\n",
              " (9.71, u'http'),\n",
              " (9.67, u'unrecovered'),\n",
              " (9.64, u'deterioration'),\n",
              " (9.63, u'late'),\n",
              " (9.63, u'conference'),\n",
              " (9.62, u'408'),\n",
              " (9.58, u'reorganizations'),\n",
              " (9.58, u'pg'),\n",
              " (9.58, u'cooler'),\n",
              " (9.57, u'trackers'),\n",
              " (9.57, u'980'),\n",
              " (9.57, u'56'),\n",
              " (9.56, u'self'),\n",
              " (9.53, u'march'),\n",
              " (9.5, u'simultaneously'),\n",
              " (9.5, u'com'),\n",
              " (9.5, u'11'),\n",
              " (9.49, u'wyndhamworldwide'),\n",
              " (9.49, u'assurances'),\n",
              " (9.47, u'challenging'),\n",
              " (9.46, u'roe'),\n",
              " (9.44, u'spin'),\n",
              " (9.44, u'refinancing'),\n",
              " (9.44, u'beneficial'),\n",
              " (9.43, u'2020'),\n",
              " (9.38, u'content'),\n",
              " (9.37, u'tours'),\n",
              " (9.37, u'geographic'),\n",
              " (9.36, u'preprint'),\n",
              " (9.36, u'eps1'),\n",
              " (9.33, u'restates'),\n",
              " (9.32, u'anchored'),\n",
              " (9.31, u'whirlwind'),\n",
              " (9.31, u'rector'),\n",
              " (9.3, u'shipments'),\n",
              " (9.3, u'9425'),\n",
              " (9.29, u'testimony'),\n",
              " (9.29, u'bunting'),\n",
              " (9.28, u'virginia'),\n",
              " (9.28, u'schedule'),\n",
              " (9.22, u'foot'),\n",
              " (9.21, u'pinnaclewest'),\n",
              " (9.21, u'nebraska'),\n",
              " (9.19, u'pnw'),\n",
              " (9.17, u'ad'),\n",
              " (9.16, u'unadjusted'),\n",
              " (9.14, u'pension'),\n",
              " (9.12, u'carrybacks'),\n",
              " (9.11, u'wayne'),\n",
              " (9.1, u'visit'),\n",
              " (9.09, u'declining'),\n",
              " (9.08, u'partnership'),\n",
              " (9.07, u'timeline'),\n",
              " (9.05, u'9872'),\n",
              " (9.04, u'registrants'),\n",
              " (9.03, u'wan'),\n",
              " (9.03, u'largest'),\n",
              " (9.03, u'cci'),\n",
              " (9.03, u'approval'),\n",
              " (9.01, u'exc'),\n",
              " (9.0, u'sdg'),\n",
              " (8.97, u'server'),\n",
              " (8.95, u'entergy'),\n",
              " (8.94, u'silk'),\n",
              " (8.94, u'joaquin'),\n",
              " (8.94, u'16'),\n",
              " (8.93, u'temperatures'),\n",
              " (8.91, u'facilities'),\n",
              " (8.9, u'macro'),\n",
              " (8.9, u'fired'),\n",
              " (8.87, u'distributions'),\n",
              " (8.85, u'west'),\n",
              " (8.85, u'assistance'),\n",
              " (8.83, u'storm'),\n",
              " (8.83, u'steels'),\n",
              " (8.83, u'mall'),\n",
              " (8.82, u'treat'),\n",
              " (8.81, u'79'),\n",
              " (8.8, u'eldorado'),\n",
              " (8.78, u'wyndham'),\n",
              " (8.78, u'wholesale'),\n",
              " (8.78, u'mpuc'),\n",
              " (8.77, u'obsolete'),\n",
              " (8.77, u'classified'),\n",
              " (8.77, u'112'),\n",
              " (8.76, u'kara'),\n",
              " (8.74, u'loyola'),\n",
              " (8.73, u'reynoldsamerican'),\n",
              " (8.72, u'smartconnect'),\n",
              " (8.7, u'natural'),\n",
              " (8.7, u'clarita'),\n",
              " (8.7, u'bearing'),\n",
              " (8.69, u'listing'),\n",
              " (8.69, u'cloud'),\n",
              " (8.67, u'18th'),\n",
              " (8.66, u'zuckerman'),\n",
              " (8.66, u'mortimer'),\n",
              " (8.66, u'94'),\n",
              " (8.66, u'60'),\n",
              " (8.64, u'884'),\n",
              " (8.62, u'socalgas'),\n",
              " (8.62, u'ethnic'),\n",
              " (8.61, u'sharing'),\n",
              " (8.6, u'herald'),\n",
              " (8.6, u'137'),\n",
              " (8.59, u'simon'),\n",
              " (8.59, u'linux'),\n",
              " (8.58, u'extinguishments'),\n",
              " (8.57, u'specimen'),\n",
              " (8.54, u'severe'),\n",
              " (8.54, u'program'),\n",
              " (8.54, u'notebook'),\n",
              " (8.53, u'venture'),\n",
              " (8.53, u'teleconference'),\n",
              " (8.53, u'economy'),\n",
              " (8.52, u'accounting'),\n",
              " (8.52, u'83'),\n",
              " (8.52, u'10'),\n",
              " (8.51, u'suggestions'),\n",
              " (8.51, u'92'),\n",
              " (8.5, u'bostonproperties'),\n",
              " (8.5, u'20'),\n",
              " (8.49, u'national'),\n",
              " (8.48, u'hat'),\n",
              " (8.48, u'788'),\n",
              " (8.46, u'computers'),\n",
              " (8.45, u'mwg'),\n",
              " (8.45, u'379'),\n",
              " (8.44, u'compromise'),\n",
              " (8.44, u'compensation'),\n",
              " (8.42, u'ventures'),\n",
              " (8.41, u'apple'),\n",
              " (8.4, u'exeloncorp'),\n",
              " (8.4, u'downstream'),\n",
              " (8.39, u'went'),\n",
              " (8.39, u'ramon'),\n",
              " (8.39, u'consolidated'),\n",
              " (8.38, u'ilife'),\n",
              " (8.38, u'higher'),\n",
              " (8.38, u'definitive'),\n",
              " (8.37, u'april'),\n",
              " (8.33, u'highwind'),\n",
              " (8.32, u'33378'),\n",
              " (8.31, u'acute'),\n",
              " (8.3, u'oppenheimer'),\n",
              " (8.29, u'consoles'),\n",
              " (8.28, u'apportionment'),\n",
              " (8.27, u'devers'),\n",
              " (8.26, u'prize'),\n",
              " (8.25, u'upstream'),\n",
              " (8.25, u'miscellaneous'),\n",
              " (8.25, u'fanning'),\n",
              " (8.25, u'cubic'),\n",
              " (8.24, u'562'),\n",
              " (8.23, u'welfare'),\n",
              " (8.23, u'held'),\n",
              " (8.23, u'65'),\n",
              " (8.22, u'tehachapi'),\n",
              " (8.22, u'chevron'),\n",
              " (8.21, u'representation'),\n",
              " (8.2, u'allocations'),\n",
              " (8.16, u'read'),\n",
              " (8.16, u'pursued'),\n",
              " (8.16, u'personally'),\n",
              " (8.16, u'detroit'),\n",
              " (8.15, u'disease'),\n",
              " (8.15, u'adjustment'),\n",
              " (8.14, u'torvalds'),\n",
              " (8.14, u'rht'),\n",
              " (8.14, u'linus'),\n",
              " (8.13, u'soa'),\n",
              " (8.13, u'sequential'),\n",
              " (8.12, u'trust'),\n",
              " (8.12, u'discover'),\n",
              " (8.1, u'pledging'),\n",
              " (8.1, u'nation'),\n",
              " (8.09, u'leonard'),\n",
              " (8.07, u'attorney'),\n",
              " (8.07, u'43'),\n",
              " (8.06, u'schedules'),\n",
              " (8.06, u'architectures'),\n",
              " (8.05, u'facsimile'),\n",
              " (8.04, u'slowing'),\n",
              " (8.04, u'9410'),\n",
              " (8.04, u'5658'),\n",
              " (8.04, u'10011'),\n",
              " (8.03, u'sre'),\n",
              " (8.03, u'redhat'),\n",
              " (8.03, u'incomegannett'),\n",
              " (8.03, u'333'),\n",
              " (8.02, u'rosemead'),\n",
              " (8.02, u'informationgannett'),\n",
              " (8.02, u'changerevenues'),\n",
              " (8.01, u'vertical'),\n",
              " (8.01, u'takes'),\n",
              " (8.01, u'mississippi'),\n",
              " (8.01, u'deteriorated'),\n",
              " (8.0, u'subsidies'),\n",
              " (8.0, u'dis'),\n",
              " (7.99, u'500kv'),\n",
              " (7.98, u'recorded'),\n",
              " (7.97, u'stimulate'),\n",
              " (7.97, u'regional'),\n",
              " (7.96, u'psri'),\n",
              " (7.95, u'883'),\n",
              " (7.95, u'76'),\n",
              " (7.94, u'scott'),\n",
              " (7.94, u'jurisdictional'),\n",
              " (7.94, u'intangible'),\n",
              " (7.93, u'schiltz'),\n",
              " (7.93, u'kschiltz'),\n",
              " (7.93, u'hopes'),\n",
              " (7.93, u'3002'),\n",
              " (7.92, u'severability'),\n",
              " (7.92, u'participate'),\n",
              " (7.9, u'showed'),\n",
              " (7.9, u'alberhill'),\n",
              " (7.89, u'ivanpah'),\n",
              " (7.89, u'bxp'),\n",
              " (7.88, u'turmoil'),\n",
              " (7.88, u'kravco'),\n",
              " (7.87, u'pensacola'),\n",
              " (7.87, u'dominions'),\n",
              " (7.86, u'2011'),\n",
              " (7.85, u'chipset'),\n",
              " (7.85, u'442'),\n",
              " (7.82, u'vulnerabilities'),\n",
              " (7.82, u'subsidiariesunaudited'),\n",
              " (7.82, u'space'),\n",
              " (7.81, u'positive'),\n",
              " (7.81, u'additional'),\n",
              " (7.8, u'redevelops'),\n",
              " (7.8, u'purple'),\n",
              " (7.8, u'inches'),\n",
              " (7.8, u'core1'),\n",
              " (7.79, u'linage'),\n",
              " (7.79, u'june'),\n",
              " (7.78, u'watch'),\n",
              " (7.77, u'schrock'),\n",
              " (7.77, u'earlier'),\n",
              " (7.76, u'subparagraph'),\n",
              " (7.76, u'pen'),\n",
              " (7.76, u'ndt'),\n",
              " (7.75, u'shelly'),\n",
              " (7.75, u'sdoran'),\n",
              " (7.75, u'objects'),\n",
              " (7.75, u'doran'),\n",
              " (7.75, u'broaden'),\n",
              " (7.75, u'7330'),\n",
              " (7.75, u'46207'),\n",
              " (7.75, u'3439'),\n",
              " (7.74, u'red'),\n",
              " (7.74, u'pardee'),\n",
              " (7.74, u'pacings'),\n",
              " (7.74, u'kundert'),\n",
              " (7.74, u'5135'),\n",
              " (7.73, u'leasable'),\n",
              " (7.73, u'165'),\n",
              " (7.72, u'package'),\n",
              " (7.72, u'measured'),\n",
              " (7.71, u'reliable'),\n",
              " (7.71, u'assignability'),\n",
              " (7.7, u'subsequently'),\n",
              " (7.7, u'spinoff'),\n",
              " (7.7, u'solicitation'),\n",
              " (7.68, u'transaction'),\n",
              " (7.68, u'dowling'),\n",
              " (7.67, u'discussions'),\n",
              " (7.66, u'unified'),\n",
              " (7.66, u'federal'),\n",
              " (7.65, u'sugar'),\n",
              " (7.65, u'networks'),\n",
              " (7.65, u'cwip'),\n",
              " (7.65, u'1273'),\n",
              " (7.64, u'deanfoods'),\n",
              " (7.62, u'obtaining'),\n",
              " (7.59, u'streem'),\n",
              " (7.59, u'initiate'),\n",
              " (7.59, u'eroded'),\n",
              " (7.59, u'dec'),\n",
              " (7.59, u'craigstreem'),\n",
              " (7.59, u'4225'),\n",
              " (7.59, u'3575'),\n",
              " (7.58, u'99'),\n",
              " (7.58, u'1970'),\n",
              " (7.57, u'pst'),\n",
              " (7.57, u'goals'),\n",
              " (7.57, u'dekatherms'),\n",
              " (7.56, u'mwh'),\n",
              " (7.56, u'millions'),\n",
              " (7.55, u'takeover'),\n",
              " (7.55, u'pinnacle'),\n",
              " (7.55, u'mccallum'),\n",
              " (7.55, u'linde'),\n",
              " (7.55, u'efforts'),\n",
              " (7.55, u'climates'),\n",
              " (7.54, u'group'),\n",
              " (7.54, u'deduct'),\n",
              " (7.53, u'safeway'),\n",
              " (7.53, u'residential'),\n",
              " (7.53, u'jose'),\n",
              " (7.53, u'hope'),\n",
              " (7.52, u'grc'),\n",
              " (7.51, u'reinvented'),\n",
              " (7.51, u'darbee'),\n",
              " (7.5, u'technological'),\n",
              " (7.5, u'mean'),\n",
              " (7.5, u'gaming'),\n",
              " (7.5, u'defaulted'),\n",
              " (7.49, u'engaged'),\n",
              " (7.48, u'manage'),\n",
              " (7.48, u'lost'),\n",
              " (7.48, u'colorado'),\n",
              " (7.46, u'terrestrial'),\n",
              " (7.45, u'462'),\n",
              " (7.43, u'sempra'),\n",
              " (7.43, u'enzyme'),\n",
              " (7.42, u'whitehurst'),\n",
              " (7.42, u'nominate'),\n",
              " (7.42, u'deductions'),\n",
              " (7.42, u'decoupled'),\n",
              " (7.42, u'4630'),\n",
              " (7.41, u'raleigh'),\n",
              " (7.4, u'schlotterbeck'),\n",
              " (7.4, u'raising'),\n",
              " (7.4, u'merrillville'),\n",
              " (7.4, u'1896'),\n",
              " (7.39, u'itunes'),\n",
              " (7.38, u'usat'),\n",
              " (7.38, u'soccer'),\n",
              " (7.38, u'neighborhood'),\n",
              " (7.38, u'headcount'),\n",
              " (7.38, u'clerical'),\n",
              " (7.37, u'vogtle'),\n",
              " (7.37, u'visibility'),\n",
              " (7.37, u'perishables'),\n",
              " (7.37, u'674'),\n",
              " (7.36, u'toughest'),\n",
              " (7.35, u'reported'),\n",
              " (7.35, u'plaisance'),\n",
              " (7.35, u'magazines'),\n",
              " (7.35, u'kovacevich'),\n",
              " (7.34, u'rounded'),\n",
              " (7.34, u'return'),\n",
              " (7.33, u'windhub'),\n",
              " (7.33, u'seoul'),\n",
              " (7.33, u'conveying'),\n",
              " (7.32, u'transferee'),\n",
              " (7.31, u'slower'),\n",
              " (7.3, u'creamers'),\n",
              " (7.3, u'7033'),\n",
              " (7.29, u'vpg'),\n",
              " (7.29, u'restriction'),\n",
              " (7.29, u'receiving'),\n",
              " (7.28, u'reacquired'),\n",
              " (7.28, u'discoverfinancial'),\n",
              " (7.27, u'settle'),\n",
              " (7.25, u'invest'),\n",
              " (7.25, u'audit'),\n",
              " (7.25, u'150'),\n",
              " (7.24, u'concealed'),\n",
              " (7.23, u'thoughtfully'),\n",
              " (7.23, u'drivers'),\n",
              " (7.22, u'compound'),\n",
              " (7.22, u'84'),\n",
              " (7.21, u'98'),\n",
              " (7.21, u'6673'),\n",
              " (7.21, u'195'),\n",
              " (7.2, u'resolution'),\n",
              " (7.2, u'console'),\n",
              " (7.19, u'grid'),\n",
              " (7.19, u'deduction'),\n",
              " (7.18, u'1502'),\n",
              " (7.17, u'worlds'),\n",
              " (7.17, u'tax'),\n",
              " (7.17, u'manthey'),\n",
              " (7.17, u'835'),\n",
              " (7.16, u'separately'),\n",
              " (7.16, u'online'),\n",
              " (7.16, u'conclusions'),\n",
              " (7.16, u'cleaning'),\n",
              " (7.16, u'avenue'),\n",
              " (7.15, u'378'),\n",
              " (7.14, u'transmitting'),\n",
              " (7.14, u'noi'),\n",
              " (7.14, u'maturities'),\n",
              " (7.14, u'cross'),\n",
              " (7.13, u'flavor'),\n",
              " (7.12, u'ecolab'),\n",
              " (7.12, u'205'),\n",
              " (7.11, u'soot'),\n",
              " (7.11, u'appendix'),\n",
              " (7.11, u'0001'),\n",
              " (7.1, u'remove'),\n",
              " (7.1, u'novel'),\n",
              " (7.1, u'50'),\n",
              " (7.1, u'004'),\n",
              " (7.09, u'volatile'),\n",
              " (7.09, u'riverwoods'),\n",
              " (7.09, u'proposed'),\n",
              " (7.08, u'comanche'),\n",
              " (7.07, u'rai'),\n",
              " (7.07, u'peters'),\n",
              " (7.07, u'ofincome'),\n",
              " (7.07, u'drapes'),\n",
              " (7.06, u'totaling'),\n",
              " (7.06, u'stretching'),\n",
              " (7.06, u'docket'),\n",
              " (7.05, u'publisher'),\n",
              " (7.05, u'dcr'),\n",
              " (7.05, u'common'),\n",
              " (7.05, u'cbd'),\n",
              " (7.04, u'warmest'),\n",
              " (7.04, u'milk'),\n",
              " (7.04, u'leased'),\n",
              " (7.04, u'herewith'),\n",
              " (7.04, u'greement'),\n",
              " (7.03, u'table4'),\n",
              " (7.03, u'riots'),\n",
              " (7.03, u'qsr'),\n",
              " (7.03, u'pge'),\n",
              " (7.03, u'perceivable'),\n",
              " (7.03, u'pencer'),\n",
              " (7.03, u'orthogon'),\n",
              " (7.03, u'beattie'),\n",
              " (7.03, u'backer'),\n",
              " (7.03, u'7610'),\n",
              " (7.03, u'3260245'),\n",
              " (7.03, u'1032'),\n",
              " (7.01, u'players'),\n",
              " (7.01, u'mckesson'),\n",
              " (7.01, u'mandated'),\n",
              " (7.01, u'esq'),\n",
              " (7.01, u'duk'),\n",
              " (7.01, u'3d'),\n",
              " (7.0, u'revises'),\n",
              " (7.0, u'retrofit'),\n",
              " (7.0, u'preceeding'),\n",
              " (7.0, u'gains'),\n",
              " (6.99, u'price'),\n",
              " (6.99, u'end'),\n",
              " (6.99, u'crf'),\n",
              " (6.99, u'516'),\n",
              " (6.98, u'creamer'),\n",
              " (6.98, u'coal2'),\n",
              " (6.97, u'premium'),\n",
              " (6.97, u'compensate'),\n",
              " (6.96, u'extinguished'),\n",
              " (6.95, u'detriment'),\n",
              " (6.94, u'operatingincome'),\n",
              " (6.94, u'assessing'),\n",
              " (6.94, u'887'),\n",
              " (6.94, u'346'),\n",
              " (6.94, u'233'),\n",
              " (6.93, u'total'),\n",
              " (6.93, u'swy'),\n",
              " (6.93, u'seasonality'),\n",
              " (6.93, u'postponement'),\n",
              " (6.93, u'paxton1'),\n",
              " (6.93, u'paxton'),\n",
              " (6.93, u'households'),\n",
              " (6.93, u'hoover1'),\n",
              " (6.93, u'addback'),\n",
              " (6.93, u'5420'),\n",
              " (6.93, u'4570'),\n",
              " (6.93, u'3832'),\n",
              " (6.92, u'nox'),\n",
              " (6.92, u'live'),\n",
              " (6.92, u'601'),\n",
              " (6.91, u'deadband'),\n",
              " (6.9, u'ignited'),\n",
              " (6.9, u'hardware'),\n",
              " (6.89, u'roger'),\n",
              " (6.89, u'months'),\n",
              " (6.89, u'integrysgroup'),\n",
              " (6.89, u'dso'),\n",
              " (6.89, u'42'),\n",
              " (6.88, u'midtown'),\n",
              " (6.88, u'edisoninvestor'),\n",
              " (6.88, u'334'),\n",
              " (6.87, u'marketable'),\n",
              " (6.87, u'earning'),\n",
              " (6.87, u'actually'),\n",
              " (6.86, u'tomahawk'),\n",
              " (6.86, u'mc'),\n",
              " (6.86, u'desktop'),\n",
              " (6.85, u'homer'),\n",
              " (6.85, u'check'),\n",
              " (6.85, u'3333'),\n",
              " (6.84, u'positioned'),\n",
              " (6.83, u'yankee'),\n",
              " (6.83, u'phones'),\n",
              " (6.83, u'hyperinflationary'),\n",
              " (6.83, u'316'),\n",
              " (6.82, u'remodels'),\n",
              " (6.82, u'aee'),\n",
              " (6.82, u'27102'),\n",
              " (6.81, u'way'),\n",
              " (6.81, u'peoples'),\n",
              " (6.81, u'narrowed'),\n",
              " (6.81, u'device'),\n",
              " (6.81, u'decline'),\n",
              " (6.8, u'salem'),\n",
              " (6.8, u'reposition'),\n",
              " (6.8, u'87'),\n",
              " (6.79, u'mw'),\n",
              " (6.79, u'gakunder2'),\n",
              " (6.79, u'freelancer'),\n",
              " (6.79, u'ehs'),\n",
              " (6.79, u'credits'),\n",
              " (6.78, u'intervenors'),\n",
              " (6.77, u'ownership'),\n",
              " (6.77, u'additives'),\n",
              " (6.76, u'waukegan'),\n",
              " (6.76, u'orders'),\n",
              " (6.76, u'dependence'),\n",
              " (6.76, u'chloraprep'),\n",
              " (6.76, u'30'),\n",
              " (6.75, u'help'),\n",
              " (6.75, u'director'),\n",
              " (6.74, u'600'),\n",
              " (6.74, u'2027'),\n",
              " (6.73, u'valley'),\n",
              " (6.73, u'september'),\n",
              " (6.73, u'orphan'),\n",
              " (6.72, u'storing'),\n",
              " (6.72, u'approve'),\n",
              " (6.72, u'53'),\n",
              " (6.71, u'undistributed'),\n",
              " (6.71, u'trading'),\n",
              " (6.71, u'normally'),\n",
              " (6.7, u'peco'),\n",
              " (6.7, u'inclusion'),\n",
              " (6.69, u'fisk'),\n",
              " (6.69, u'47583'),\n",
              " (6.68, u'2014'),\n",
              " (6.67, u'restrict'),\n",
              " (6.66, u'xeon'),\n",
              " (6.66, u'sps'),\n",
              " (6.66, u'release'),\n",
              " (6.66, u'emg1'),\n",
              " (6.66, u'clipper'),\n",
              " (6.66, u'40'),\n",
              " (6.65, u'marguerite'),\n",
              " (6.65, u'ebay'),\n",
              " (6.65, u'copel'),\n",
              " (6.64, u'statement'),\n",
              " (6.64, u'scheduled'),\n",
              " (6.64, u'environmental'),\n",
              " (6.63, u'vis'),\n",
              " (6.63, u'raw'),\n",
              " (6.63, u'hoyt'),\n",
              " (6.63, u'founder'),\n",
              " (6.62, u'so2'),\n",
              " (6.62, u'dfs'),\n",
              " (6.62, u'applications'),\n",
              " (6.62, u'andcaptivate'),\n",
              " (6.61, u'accessories'),\n",
              " (6.61, u'85'),\n",
              " (6.6, u'winston'),\n",
              " (6.6, u'embargoes'),\n",
              " (6.6, u'demand'),\n",
              " (6.6, u'altering'),\n",
              " (6.59, u'segregation'),\n",
              " (6.59, u'encumbers'),\n",
              " (6.59, u'143'),\n",
              " (6.58, u'proceed'),\n",
              " (6.58, u'operational'),\n",
              " (6.58, u'occurrences'),\n",
              " (6.58, u'entitles'),\n",
              " (6.57, u'removing'),\n",
              " (6.57, u'cautious'),\n",
              " (6.56, u'worsening'),\n",
              " (6.56, u'mitral'),\n",
              " (6.56, u'basic'),\n",
              " (6.55, u'trusts'),\n",
              " (6.55, u'today'),\n",
              " (6.55, u'3004'),\n",
              " (6.54, u'tropical'),\n",
              " (6.53, u'underpayments'),\n",
              " (6.53, u'8809'),\n",
              " (6.53, u'203'),\n",
              " (6.52, u'noninterest'),\n",
              " (6.52, u'loop'),\n",
              " (6.52, u'association'),\n",
              " (6.51, u'mehok'),\n",
              " (6.51, u'firstsolar'),\n",
              " (6.51, u'factset'),\n",
              " (6.51, u'david_mehok'),\n",
              " (6.51, u'cart'),\n",
              " (6.51, u'carryback'),\n",
              " (6.51, u'aminopyralid'),\n",
              " (6.51, u'8054'),\n",
              " (6.5, u'trustees'),\n",
              " (6.5, u'rubber'),\n",
              " (6.5, u'plaza'),\n",
              " (6.5, u'jboss'),\n",
              " (6.5, u'confirmation'),\n",
              " (6.5, u'capstone'),\n",
              " (6.5, u'3136'),\n",
              " (6.49, u'vermont'),\n",
              " (6.49, u'taped'),\n",
              " (6.49, u'solutions'),\n",
              " (6.49, u'replaces'),\n",
              " (6.47, u'sphere'),\n",
              " (6.47, u'rider'),\n",
              " (6.47, u'offset'),\n",
              " (6.47, u'focal'),\n",
              " (6.46, u'retained'),\n",
              " (6.46, u'alleghenytechnologies'),\n",
              " (6.46, u'4broadcasting'),\n",
              " (6.45, u'redeemable'),\n",
              " (6.45, u'disparities'),\n",
              " (6.45, u'9000'),\n",
              " (6.45, u'57'),\n",
              " (6.44, u'reynolds'),\n",
              " (6.44, u'netapp'),\n",
              " (6.43, u'subscription'),\n",
              " (6.43, u'mccorkindale'),\n",
              " (6.43, u'hyde'),\n",
              " (6.43, u'delight'),\n",
              " (6.43, u'benefitaccess'),\n",
              " (6.42, u'primary'),\n",
              " (6.41, u'redefine'),\n",
              " (6.41, u'oronite'),\n",
              " (6.41, u'mccormick'),\n",
              " (6.41, u'increasingly'),\n",
              " (6.41, u'exelon'),\n",
              " (6.41, u'ebit'),\n",
              " (6.41, u'disappointing'),\n",
              " (6.4, u'spearheading'),\n",
              " (6.4, u'motivate'),\n",
              " (6.4, u'entergys'),\n",
              " (6.39, u'ytd'),\n",
              " (6.39, u'traumatic'),\n",
              " (6.39, u'nussbaum'),\n",
              " (6.39, u'foreseeable'),\n",
              " (6.39, u'386'),\n",
              " (6.39, u'185'),\n",
              " (6.38, u'superior'),\n",
              " (6.38, u'seeattachment'),\n",
              " (6.38, u'sbusiness'),\n",
              " (6.38, u'intuitive'),\n",
              " (6.37, u'incidents'),\n",
              " (6.37, u'digital'),\n",
              " (6.37, u'81'),\n",
              " (6.36, u'pressuring'),\n",
              " (6.36, u'newspaper'),\n",
              " (6.36, u'humidity'),\n",
              " (6.36, u'ensures'),\n",
              " (6.36, u'dara'),\n",
              " (6.35, u'preserved'),\n",
              " (6.35, u'mr'),\n",
              " (6.35, u'completion'),\n",
              " (6.35, u'62'),\n",
              " (6.34, u'emg'),\n",
              " (6.34, u'diabetes'),\n",
              " (6.34, u'929'),\n",
              " (6.33, u'trials'),\n",
              " (6.33, u'executors'),\n",
              " (6.33, u'entered'),\n",
              " (6.33, u'delaware'),\n",
              " (6.32, u'spgprj'),\n",
              " (6.32, u'046875'),\n",
              " (6.31, u'diners'),\n",
              " (6.3, u'purchased'),\n",
              " (6.3, u'partially'),\n",
              " (6.29, u'px'),\n",
              " (6.29, u'ntap'),\n",
              " (6.29, u'dsm'),\n",
              " (6.28, u'insite'),\n",
              " (6.28, u'evening'),\n",
              " (6.28, u'eir'),\n",
              " (6.28, u'alloys'),\n",
              " (6.27, u'treas'),\n",
              " (6.27, u'statutory'),\n",
              " (6.27, u'rolls'),\n",
              " (6.27, u'corporate'),\n",
              " (6.26, u'1other'),\n",
              " (6.25, u'paypal'),\n",
              " (6.25, u'intuitivesurgical'),\n",
              " (6.25, u'hvac'),\n",
              " (6.25, u'enclosed'),\n",
              " (6.25, u'craver'),\n",
              " (6.25, u'66'),\n",
              " (6.24, u'pheasant'),\n",
              " (6.24, u'issuances'),\n",
              " (6.24, u'irhome'),\n",
              " (6.24, u'cost'),\n",
              " (6.24, u'8753'),\n",
              " (6.23, u'transferor'),\n",
              " (6.23, u'longer'),\n",
              " (6.23, u'game'),\n",
              " (6.23, u'disabled'),\n",
              " (6.22, u'momentum'),\n",
              " (6.22, u'incentive'),\n",
              " (6.22, u'forums'),\n",
              " (6.22, u'exclusively'),\n",
              " (6.21, u'declines'),\n",
              " (6.21, u'briefly'),\n",
              " (6.21, u'blood'),\n",
              " (6.21, u'anchors'),\n",
              " (6.2, u'size'),\n",
              " (6.2, u'delays'),\n",
              " (6.2, u'conveniens'),\n",
              " (6.19, u'separated'),\n",
              " (6.19, u'mover'),\n",
              " (6.19, u'demonstrable'),\n",
              " (6.19, u'2990'),\n",
              " (6.18, u'pscw'),\n",
              " (6.18, u'nervous'),\n",
              " (6.18, u'khosrowshahi'),\n",
              " (6.18, u'dispositions'),\n",
              " (6.18, u'cfo'),\n",
              " (6.18, u'323'),\n",
              " (6.17, u'reclassification'),\n",
              " (6.17, u'leave'),\n",
              " (6.17, u'hipaa'),\n",
              " (6.17, u'circulation'),\n",
              " (6.16, u'workpapers'),\n",
              " (6.16, u'unitary'),\n",
              " (6.16, u'originator'),\n",
              " (6.16, u'nathan'),\n",
              " (6.16, u'commercially'),\n",
              " (6.15, u'powerton'),\n",
              " (6.15, u'isrg'),\n",
              " (6.15, u'devaluation'),\n",
              " (6.14, u'melvin'),\n",
              " (6.14, u'dte'),\n",
              " (6.14, u'coconut'),\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "9-MuZV0CO9o9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### DNN Using Numeric + Text Features\n",
        "\n",
        "49.17% \n",
        "\n",
        "This model uses a naive approach of concatenating all 2000 text features to the 13 numeric features and feeding them all at once to the DNN"
      ]
    },
    {
      "metadata": {
        "id": "Yl2cMemyO9pD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = np.hstack([x_train_text.toarray(),traindf[FEATURES]])\n",
        "x_val = np.hstack([x_val_text.toarray(),evaldf[FEATURES]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jN6QkISAO9pI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "829d9f57-850f-4bac-dad5-46640b4604bb"
      },
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "dropout_rate=0.5\n",
        "units=64\n",
        "input_shape = x_train.shape[1:]\n",
        "num_classes=3\n",
        "loss = 'sparse_categorical_crossentropy'\n",
        "learning_rate=1e-3\n",
        "epochs=10\n",
        "batch_size=128\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Embedding\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "np.random.seed(SEED)\n",
        "tf.set_random_seed(SEED) \n",
        "\n",
        "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(Dense(units=units, input_shape=input_shape, activation='relu', kernel_initializer=tf.glorot_uniform_initializer(seed=SEED)))\n",
        "model.add(Dropout(rate=dropout_rate,seed=SEED))\n",
        "model.add(Dense(units=num_classes, activation='softmax', kernel_initializer=tf.glorot_uniform_initializer(seed=SEED)))\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=3)]\n",
        "\n",
        "history = model.fit(\n",
        "        x_train,\n",
        "        traindf.label_numeric,\n",
        "        callbacks=callbacks,\n",
        "        epochs=epochs,\n",
        "        validation_data=(x_val, evaldf.label_numeric),\n",
        "        verbose=2,  # Logs once per epoch.\n",
        "        batch_size=batch_size)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11530 samples, validate on 2821 samples\n",
            "Epoch 1/10\n",
            " - 1s - loss: 1.3263 - acc: 0.3964 - val_loss: 1.1270 - val_acc: 0.4612\n",
            "Epoch 2/10\n",
            " - 1s - loss: 1.1249 - acc: 0.4435 - val_loss: 1.1127 - val_acc: 0.4573\n",
            "Epoch 3/10\n",
            " - 1s - loss: 1.0918 - acc: 0.4668 - val_loss: 1.0794 - val_acc: 0.4810\n",
            "Epoch 4/10\n",
            " - 1s - loss: 1.0749 - acc: 0.4723 - val_loss: 1.0914 - val_acc: 0.4800\n",
            "Epoch 5/10\n",
            " - 1s - loss: 1.0496 - acc: 0.4919 - val_loss: 1.0545 - val_acc: 0.4832\n",
            "Epoch 6/10\n",
            " - 1s - loss: 1.0350 - acc: 0.4997 - val_loss: 1.0732 - val_acc: 0.4747\n",
            "Epoch 7/10\n",
            " - 1s - loss: 1.0296 - acc: 0.5088 - val_loss: 1.0711 - val_acc: 0.4828\n",
            "Epoch 8/10\n",
            " - 1s - loss: 1.0138 - acc: 0.5210 - val_loss: 1.0600 - val_acc: 0.4917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6wTVTKoMO9pM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "776ce28c-d4d3-4e84-ae95-23ab0f9a5874"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 64)                128960    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 129,155\n",
            "Trainable params: 129,155\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mueVCRv8O9pP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### With Embedding\n",
        "\n",
        "52.14% (after 5 epochs)\n",
        "\n",
        "If we take a more nuanced approach of first learning an 50 dimensional embedding of the 2000 text features, then concatenating the embedded representation with the numeric features, we get better performance"
      ]
    },
    {
      "metadata": {
        "id": "Xp1KTSIIO9pQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "d35576ee-ab3a-489a-d5e3-880f26cb13f3"
      },
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "EMBEDDING_DIM = 50\n",
        "dropout_rate=0.5\n",
        "units=64\n",
        "input_shape = x_train.shape[1:]\n",
        "num_classes=3\n",
        "loss = 'sparse_categorical_crossentropy'\n",
        "learning_rate=1e-3\n",
        "epochs=10\n",
        "batch_size=128\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Embedding\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "np.random.seed(SEED)\n",
        "tf.set_random_seed(SEED) \n",
        "\n",
        "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "# using keras functional API instead of sequential API to insert surprise upstream of embedding.\n",
        "text_input = keras.Input(shape=x_train_text.shape[1:], dtype='float32', name='text_input')\n",
        "text_embedded = Dense(units=EMBEDDING_DIM, activation='relu', kernel_initializer=tf.glorot_uniform_initializer(seed=SEED))(text_input)\n",
        "auxiliary_input = keras.Input(shape=(len(FEATURES),), name='auxiliary_input')\n",
        "x = keras.layers.concatenate([text_embedded, auxiliary_input])\n",
        "x = Dense(units=units, activation='relu', kernel_initializer=tf.glorot_uniform_initializer(seed=SEED))(x)\n",
        "x = Dropout(rate=dropout_rate, seed=SEED)(x)\n",
        "output = Dense(units=num_classes, activation='softmax', kernel_initializer=tf.glorot_uniform_initializer(seed=SEED))(x)\n",
        "model = keras.Model(inputs=[text_input,auxiliary_input], outputs=output)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\n",
        "\n",
        "history = model.fit(\n",
        "        {'text_input':x_train_text, 'auxiliary_input':traindf[FEATURES]},\n",
        "        traindf.label_numeric,\n",
        "        epochs=epochs,\n",
        "        validation_data=(\n",
        "            {'text_input':x_val_text, 'auxiliary_input':evaldf[FEATURES]}, \n",
        "            evaldf.label_numeric),\n",
        "        verbose=2,  # Logs once per epoch.\n",
        "        batch_size=batch_size)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11530 samples, validate on 2821 samples\n",
            "Epoch 1/10\n",
            " - 1s - loss: 1.6352 - acc: 0.4127 - val_loss: 1.2850 - val_acc: 0.4860\n",
            "Epoch 2/10\n",
            " - 1s - loss: 1.3073 - acc: 0.4421 - val_loss: 1.2334 - val_acc: 0.4821\n",
            "Epoch 3/10\n",
            " - 1s - loss: 1.2276 - acc: 0.4552 - val_loss: 1.1680 - val_acc: 0.5055\n",
            "Epoch 4/10\n",
            " - 1s - loss: 1.1736 - acc: 0.4753 - val_loss: 1.1531 - val_acc: 0.5055\n",
            "Epoch 5/10\n",
            " - 1s - loss: 1.1524 - acc: 0.4925 - val_loss: 1.1309 - val_acc: 0.5214\n",
            "Epoch 6/10\n",
            " - 1s - loss: 1.1222 - acc: 0.4958 - val_loss: 1.1166 - val_acc: 0.5126\n",
            "Epoch 7/10\n",
            " - 1s - loss: 1.1114 - acc: 0.4996 - val_loss: 1.1202 - val_acc: 0.5133\n",
            "Epoch 8/10\n",
            " - 1s - loss: 1.0861 - acc: 0.5091 - val_loss: 1.0996 - val_acc: 0.5105\n",
            "Epoch 9/10\n",
            " - 1s - loss: 1.0709 - acc: 0.5109 - val_loss: 1.0941 - val_acc: 0.5108\n",
            "Epoch 10/10\n",
            " - 1s - loss: 1.0686 - acc: 0.5214 - val_loss: 1.0864 - val_acc: 0.4981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jA0cD9FMe5YV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "29776eaa-d7a5-4502-a411-a3077f081218"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_input (InputLayer)         (None, 2000)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 50)           100050      text_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "auxiliary_input (InputLayer)    (None, 14)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 64)           0           dense_4[0][0]                    \n",
            "                                                                 auxiliary_input[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 64)           4160        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 64)           0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 3)            195         dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 104,405\n",
            "Trainable params: 104,405\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7zqq_hva81i2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Package as Estimator\n",
        "\n",
        "This allows for distributed training and easy deployment of REST API.\n",
        "\n",
        "We create a task.py to parse command line parameters and a model.py for the remaining code.\n",
        "\n",
        "Note here we remove the single-threaded constraint which allows faster training but no longer guarantees reproducibility"
      ]
    },
    {
      "metadata": {
        "id": "eBpA2Qih-f-f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "10486053-f682-426d-ce76-01572644d025"
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "mkdir stockprediction\n",
        "touch stockprediction/__init__.py"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘stockprediction’: File exists\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "xZ4No58voKR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "650350c3-a638-448d-bb74-4c4ece6574e2"
      },
      "cell_type": "code",
      "source": [
        "%%writefile stockprediction/task.py\n",
        "\n",
        "import argparse\n",
        "from . import model\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # parse command line arguments\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        '--output_dir',\n",
        "        help='location to write checkpoints and export models',\n",
        "        required=True\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        '--data_path',\n",
        "        help='can be a local path or a GCS url (gs://...)',\n",
        "        required=True\n",
        "    )\n",
        "\n",
        "    args, _ = parser.parse_known_args()\n",
        "    hparams = args.__dict__\n",
        "    \n",
        "    model.train_and_evaluate(hparams)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting stockprediction/task.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zWrlqHkW9tm0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "059b442e-2743-4189-aa55-74df88fb97e3"
      },
      "cell_type": "code",
      "source": [
        "%%writefile stockprediction/model.py\n",
        "\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Embedding\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "tf.logging.set_verbosity('INFO')\n",
        "\n",
        "### 0. Hyperparameters\n",
        "LEARNING_RATE=1e-3 # .001\n",
        "EPOCHS=10\n",
        "BATCH_SIZE=128\n",
        "SEED=1\n",
        "EMBEDDING_DIM = 50\n",
        "DROPOUT_RATE=0.5\n",
        "UNITS=64 # units in each dense layer\n",
        "NUM_CLASSES=3\n",
        "TOP_K = 2000 # Select top 'k' of the vectorized features.\n",
        "NGRAM_RANGE = (1, 1) # Range (inclusive) of n-gram sizes for tokenizing text.\n",
        "MIN_DOCUMENT_FREQUENCY = 5 # Minimum document/corpus frequency below which a token will be discarded.\n",
        "\n",
        "np.random.seed(SEED)\n",
        "tf.set_random_seed(SEED) \n",
        "\n",
        "### 1. Load Data\n",
        "def load_data(data_path):\n",
        "  dfXy = pd.read_csv(data_path)\n",
        "  dfXy = dfXy.dropna() # remove rows with null values\n",
        "\n",
        "  #Create Train/Eval Datasets\n",
        "  np.random.seed(0) # this is the only seed that isn't parameterized because the data split should never change\n",
        "  msk = np.random.rand(len(dfXy)) < 0.8 \n",
        "  traindf = dfXy[msk].copy()\n",
        "  evaldf = dfXy[~msk].copy()\n",
        "\n",
        "  #Convert string labels to numeric\n",
        "  traindf['label_numeric'] = traindf.label.apply(lambda x: {'DOWN': 0, 'STAY': 1, 'UP':2}[x])\n",
        "  evaldf['label_numeric'] = evaldf.label.apply(lambda x: {'DOWN': 0, 'STAY': 1, 'UP':2}[x])\n",
        "\n",
        "  return traindf, evaldf\n",
        "\n",
        "### 2. Vectorize text\n",
        "def vectorize_text(traindf, evaldf):\n",
        "  vectorizer = CountVectorizer(\n",
        "      ngram_range=NGRAM_RANGE,\n",
        "      strip_accents='unicode',\n",
        "      stop_words='english',\n",
        "      min_df=MIN_DOCUMENT_FREQUENCY,\n",
        "      ) # returns sklearn.feature_extraction.text.CountVectorizer\n",
        "\n",
        "  x_train_text = vectorizer.fit_transform(traindf.text) #takes ~2min, returns scipy.sparse.csr.csr_matrix\n",
        "  x_val_text = vectorizer.transform(evaldf.text)\n",
        "\n",
        "  selector = SelectKBest(f_classif, k=min(TOP_K, x_train_text.shape[1]))\n",
        "  selector.fit(x_train_text, traindf.label_numeric)\n",
        "  x_train_text = selector.transform(x_train_text)\n",
        "  x_val_text = selector.transform(x_val_text)\n",
        "  return x_train_text, x_val_text\n",
        "\n",
        "### 3. Model Code\n",
        "def build_model(num_numeric_features,num_text_features):\n",
        "  # using keras functional API instead of sequential API to insert surprise upstream of embedding.\n",
        "  text_input = keras.Input(shape=num_text_features, dtype='float32', name='text_input')\n",
        "  text_embedded = Dense(units=EMBEDDING_DIM, activation='relu', kernel_initializer=tf.glorot_uniform_initializer(seed=SEED))(text_input)\n",
        "  auxiliary_input = keras.Input(shape=(num_numeric_features,), name='auxiliary_input')\n",
        "  x = keras.layers.concatenate([text_embedded, auxiliary_input])\n",
        "  x = Dense(units=UNITS, activation='relu', kernel_initializer=tf.glorot_uniform_initializer(seed=SEED))(x)\n",
        "  x = Dropout(rate=DROPOUT_RATE, seed=SEED)(x)\n",
        "  output = Dense(units=NUM_CLASSES, activation='softmax', kernel_initializer=tf.glorot_uniform_initializer(seed=SEED))(x)\n",
        "  model = keras.Model(inputs=[text_input,auxiliary_input], outputs=output)\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=LEARNING_RATE)\n",
        "  model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "  return model\n",
        "\n",
        "### 4. Input Function\n",
        "\n",
        "def input_fn(features, labels, mode):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "    \n",
        "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "    dataset = dataset.shuffle(50000,seed=SEED).repeat(-1)\n",
        "\n",
        "  # Shuffle, repeat, and batch the examples.\n",
        "  return dataset.batch(BATCH_SIZE)\n",
        "\n",
        "\n",
        "def train_and_evaluate(hparams):\n",
        "  ### 1. Load Data\n",
        "  traindf, evaldf = load_data(hparams['data_path'])\n",
        "  ### 2. Vectorize text\n",
        "  x_train_text, x_val_text = vectorize_text(traindf, evaldf)\n",
        "\n",
        "  # Select Numeric Features\n",
        "  ix_price_features = traindf.columns.str.contains('close_')\n",
        "  price_features = traindf.columns[ix_price_features].tolist()\n",
        "  price_features.remove('close_values_prior_260') # For RNN, which is a list. We don't want.\n",
        "  FEATURES = price_features + ['surprise'] \n",
        " \n",
        "  ### 3. Build Estimator\n",
        "  model = build_model(\n",
        "    num_numeric_features=len(FEATURES),\n",
        "    num_text_features=x_train_text.shape[1:])\n",
        "  run_config = tf.estimator.RunConfig(save_checkpoints_steps=100, tf_random_seed=SEED)\n",
        "  estimator = tf.keras.estimator.model_to_estimator(keras_model=model, model_dir=hparams['output_dir'], config=run_config)\n",
        "\n",
        "  # Create TrainSpec\n",
        "  train_steps = EPOCHS * len(traindf) / BATCH_SIZE\n",
        "  train_spec = tf.estimator.TrainSpec(\n",
        "      input_fn=lambda: input_fn(\n",
        "          {'text_input':x_train_text.toarray(), 'auxiliary_input':traindf[FEATURES]},\n",
        "          traindf.label_numeric,\n",
        "          mode=tf.estimator.ModeKeys.TRAIN),\n",
        "      max_steps=train_steps\n",
        "  )\n",
        "\n",
        "  # Create EvalSpec\n",
        "  exporter = None #tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
        "  eval_spec = tf.estimator.EvalSpec(\n",
        "      input_fn=lambda: input_fn(\n",
        "          {'text_input':x_val_text.toarray(), 'auxiliary_input':evaldf[FEATURES]},\n",
        "          evaldf.label_numeric,\n",
        "          mode=tf.estimator.ModeKeys.EVAL),\n",
        "      steps=None,\n",
        "      exporters=exporter,\n",
        "      start_delay_secs=10,\n",
        "      throttle_secs=1\n",
        "  )\n",
        "\n",
        "  # Start training\n",
        "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting stockprediction/model.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RH9I7D49dPRt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test Package Locally"
      ]
    },
    {
      "metadata": {
        "id": "1QodwwY-XgH0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2352
        },
        "outputId": "df19f842-2c69-4138-ab89-2e0bcc3f2ae2"
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "OUTDIR='model_trained'\n",
        "rm -rf $OUTDIR\n",
        "gcloud ml-engine local train \\\n",
        "   --module-name=stockprediction.task \\\n",
        "   --package-path=${PWD}/stockprediction \\\n",
        "   -- \\\n",
        "   --output_dir=$OUTDIR \\\n",
        "   --data_path='data.csv'"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {}, u'job': {u'args': [u'--output_dir=model_trained', u'--data_path=data.csv'], u'job_name': u'stockprediction.task'}, u'task': {}}\n",
            "INFO:tensorflow:Using the Keras model provided.\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7096b75dd0>, '_evaluation_master': '', '_save_checkpoints_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': 1, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': 'model_trained', '_train_distribute': None, '_save_summary_steps': 100}\n",
            "2018-10-10 19:40:52.436816: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 100 or save_checkpoints_secs None.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from model_trained/keras_model.ckpt\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "tcmalloc: large alloc 1233903616 bytes == 0x5557535a6000 @  0x7f70bdd78615 0x555678490042 0x555678495512 0x5556784950cb 0x5556784d6912 0x5556784bc0e8 0x5556784b48ca 0x5556784bc7d3 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784b48ca 0x5556784bc24e 0x5556784b48ca 0x5556784bc24e\n",
            "tcmalloc: large alloc 1542381568 bytes == 0x5556e9726000 @  0x7f70bdd78615 0x555678490042 0x555678495512 0x5556784950cb 0x5556784d6912 0x5556784bc0e8 0x5556784b48ca 0x5556784bc7d3 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784b48ca 0x5556784bc24e 0x5556784b48ca 0x5556784bc24e\n",
            "tcmalloc: large alloc 1927979008 bytes == 0x555745614000 @  0x7f70bdd78615 0x555678490042 0x555678495512 0x5556784950cb 0x5556784d6912 0x5556784bc0e8 0x5556784b48ca 0x5556784bc7d3 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784bbd72 0x5556784b48ca 0x5556784bc24e 0x5556784b48ca 0x5556784bc24e\n",
            "INFO:tensorflow:Saving checkpoints for 0 into model_trained/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.8673337, step = 1\n",
            "INFO:tensorflow:Saving checkpoints for 100 into model_trained/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-10-19:41:37\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from model_trained/model.ckpt-100\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-10-19:41:38\n",
            "INFO:tensorflow:Saving dict for global step 100: acc = 0.43131796, global_step = 100, loss = 1.2809781\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: model_trained/model.ckpt-100\n",
            "INFO:tensorflow:global_step/sec: 25.0346\n",
            "INFO:tensorflow:loss = 1.1377695, step = 101 (3.995 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 200 into model_trained/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-10-19:41:42\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from model_trained/model.ckpt-200\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-10-19:41:42\n",
            "INFO:tensorflow:Saving dict for global step 200: acc = 0.43641305, global_step = 200, loss = 1.2200806\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: model_trained/model.ckpt-200\n",
            "INFO:tensorflow:global_step/sec: 26.0694\n",
            "INFO:tensorflow:loss = 1.14014, step = 201 (3.836 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 300 into model_trained/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-10-19:41:48\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from model_trained/model.ckpt-300\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-10-19:41:49\n",
            "INFO:tensorflow:Saving dict for global step 300: acc = 0.44660327, global_step = 300, loss = 1.199908\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 300: model_trained/model.ckpt-300\n",
            "INFO:tensorflow:global_step/sec: 15.1627\n",
            "INFO:tensorflow:loss = 1.1819875, step = 301 (6.595 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 400 into model_trained/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-10-19:41:56\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from model_trained/model.ckpt-400\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-10-19:41:57\n",
            "INFO:tensorflow:Saving dict for global step 400: acc = 0.39755437, global_step = 400, loss = 1.1499689\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 400: model_trained/model.ckpt-400\n",
            "INFO:tensorflow:global_step/sec: 12.0771\n",
            "INFO:tensorflow:loss = 1.2105649, step = 401 (8.280 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 500 into model_trained/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-10-19:42:06\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from model_trained/model.ckpt-500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-10-19:42:07\n",
            "INFO:tensorflow:Saving dict for global step 500: acc = 0.4413723, global_step = 500, loss = 1.1324309\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: model_trained/model.ckpt-500\n",
            "INFO:tensorflow:global_step/sec: 10.7002\n",
            "INFO:tensorflow:loss = 1.0821375, step = 501 (9.346 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 600 into model_trained/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-10-19:42:15\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from model_trained/model.ckpt-600\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-10-19:42:16\n",
            "INFO:tensorflow:Saving dict for global step 600: acc = 0.29422554, global_step = 600, loss = 1.1490422\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 600: model_trained/model.ckpt-600\n",
            "INFO:tensorflow:global_step/sec: 11.1439\n",
            "INFO:tensorflow:loss = 1.1411177, step = 601 (8.973 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 700 into model_trained/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-10-19:42:22\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from model_trained/model.ckpt-700\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-10-19:42:23\n",
            "INFO:tensorflow:Saving dict for global step 700: acc = 0.4738451, global_step = 700, loss = 1.1180876\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 700: model_trained/model.ckpt-700\n",
            "INFO:tensorflow:global_step/sec: 13.8441\n",
            "INFO:tensorflow:loss = 1.0576413, step = 701 (7.223 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 800 into model_trained/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-10-19:42:29\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from model_trained/model.ckpt-800\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-10-19:42:29\n",
            "INFO:tensorflow:Saving dict for global step 800: acc = 0.33994564, global_step = 800, loss = 1.0900689\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 800: model_trained/model.ckpt-800\n",
            "INFO:tensorflow:global_step/sec: 14.9221\n",
            "INFO:tensorflow:loss = 1.1023781, step = 801 (6.701 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 900 into model_trained/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-10-19:42:36\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from model_trained/model.ckpt-900\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-10-19:42:37\n",
            "INFO:tensorflow:Saving dict for global step 900: acc = 0.39008152, global_step = 900, loss = 1.0924336\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 900: model_trained/model.ckpt-900\n",
            "INFO:tensorflow:Loss for final step: 1.064231.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "gIganuIccNBF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train on CMLE\n",
        "\n",
        "Here we use a GCS hosted data.csv as our 'data_path' so that our CMLE service account can access it from the cloud. \n",
        "\n",
        "We use the https:// prefix as opposed to gs:// so that the pandas.read_csv() method can access it. \n",
        "\n",
        "Alternatively we could have used the GCS python client to first download the file to the cloud machine and then read as a local file using pandas.read_csv()"
      ]
    },
    {
      "metadata": {
        "id": "Z726mzxPZk2A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "74a52eff-199b-490c-8d72-1c0ec8c250af"
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "TFVERSION='1.10'\n",
        "BUCKET='vijays-sandbox'\n",
        "OUTDIR=gs://${BUCKET}/stockprediction/trained/\n",
        "JOBNAME=stockprediction_$(date -u +%y%m%d_%H%M%S)\n",
        "REGION=us-central1\n",
        "gsutil -m rm -rf $OUTDIR\n",
        "gcloud ml-engine jobs submit training $JOBNAME \\\n",
        " --region=$REGION \\\n",
        " --module-name=stockprediction.task \\\n",
        " --package-path=${PWD}/stockprediction \\\n",
        " --job-dir=$OUTDIR \\\n",
        " --scale-tier=BASIC_GPU \\\n",
        " --runtime-version=$TFVERSION \\\n",
        " -- \\\n",
        " --output_dir=$OUTDIR \\\n",
        " --data_path='https://storage.googleapis.com/cloud-training-demos/courses/machine_learning/asl_review_project/data.csv'"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jobId: stockprediction_181010_194243\n",
            "state: QUEUED\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Removing gs://vijays-sandbox/stockprediction/trained/#1539199732481688...\n",
            "Removing gs://vijays-sandbox/stockprediction/trained/graph.pbtxt#1539199580021405...\n",
            "Removing gs://vijays-sandbox/stockprediction/trained/checkpoint#1539199734505208...\n",
            "Removing gs://vijays-sandbox/stockprediction/trained/model.ckpt-500.data-00000-of-00001#1539199664337415...\n",
            "Removing gs://vijays-sandbox/stockprediction/trained/eval/#1539199608843599...\n",
            "Removing gs://vijays-sandbox/stockprediction/trained/model.ckpt-500.index#1539199665162399...\n",
            "Removing gs://vijays-sandbox/stockprediction/trained/eval/events.out.tfevents.1539199609.cmle-training-3295948689154592322#1539199742803891...\n",
            "Removing gs://vijays-sandbox/stockprediction/trained/events.out.tfevents.1539199544.cmle-training-3295948689154592322#1539199750238332...\n",
            "Removing gs://vijays-sandbox/stockprediction/trained/model.ckpt-600.data-00000-of-00001#1539199687446089...\n",
            "Removing gs://vijays-sandbox/stockprediction/trained/model.ckpt-500.meta#1539199672021685...\n",
            "Removing gs://vijays-sandbox/stockprediction/trained/model.ckpt-600.index#1539199687846277...\n",
            "Removing gs://vijays-sandbox/stockprediction/trained/model.ckpt-600.meta#1539199693605537...\n",
            "/ [1/22 objects]   4% Done                                                      \r/ [2/22 objects]   9% Done                                                      \r/ [3/22 objects]  13% Done                                                      \rRemoving gs://vijays-sandbox/stockprediction/trained/model.ckpt-700.data-00000-of-00001#1539199702173179...\n",
            "/ [4/22 objects]  18% Done                                                      \rRemoving gs://vijays-sandbox/stockprediction/trained/model.ckpt-700.index#1539199702575616...\n",
            "/ [5/22 objects]  22% Done                                                      \rRemoving gs://vijays-sandbox/stockprediction/trained/model.ckpt-700.meta#1539199708191635...\n",
            "Removing gs://vijays-sandbox/stockprediction/trained/model.ckpt-800.data-00000-of-00001#1539199717930802...\n",
            "/ [6/22 objects]  27% Done                                                      \rRemoving gs://vijays-sandbox/stockprediction/trained/model.ckpt-800.index#1539199718544546...\n",
            "Removing gs://vijays-sandbox/stockprediction/trained/model.ckpt-800.meta#1539199723862928...\n",
            "Removing gs://vijays-sandbox/stockprediction/trained/model.ckpt-900.data-00000-of-00001#1539199732977324...\n",
            "/ [7/22 objects]  31% Done                                                      \r/ [8/22 objects]  36% Done                                                      \r/ [9/22 objects]  40% Done                                                      \rRemoving gs://vijays-sandbox/stockprediction/trained/model.ckpt-900.index#1539199733436519...\n",
            "/ [10/22 objects]  45% Done                                                     \rRemoving gs://vijays-sandbox/stockprediction/trained/model.ckpt-900.meta#1539199738161628...\n",
            "Removing gs://vijays-sandbox/stockprediction/trained/packages/5a45e6a8a4ff48b6e829d99f78b095b3b8aabdf630b1030eba6068371114335d/stockprediction-0.0.0.tar.gz#1539199354912606...\n",
            "/ [11/22 objects]  50% Done                                                     \r/ [12/22 objects]  54% Done                                                     \r/ [13/22 objects]  59% Done                                                     \r/ [14/22 objects]  63% Done                                                     \r/ [15/22 objects]  68% Done                                                     \r/ [16/22 objects]  72% Done                                                     \r/ [17/22 objects]  77% Done                                                     \r/ [18/22 objects]  81% Done                                                     \r/ [19/22 objects]  86% Done                                                     \r/ [20/22 objects]  90% Done                                                     \r/ [21/22 objects]  95% Done                                                     \r/ [22/22 objects] 100% Done                                                     \r\n",
            "Operation completed over 22 objects.                                             \n",
            "Job [stockprediction_181010_194243] submitted successfully.\n",
            "Your job is still active. You may view the status of your job with the command\n",
            "\n",
            "  $ gcloud ml-engine jobs describe stockprediction_181010_194243\n",
            "\n",
            "or continue streaming the logs with the command\n",
            "\n",
            "  $ gcloud ml-engine jobs stream-logs stockprediction_181010_194243\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "BPPp5vPmdL3b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Copyright 2018 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
      ]
    }
  ]
}